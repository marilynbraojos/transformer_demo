{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marilynbraojos/transformer_demo/blob/main/gpt_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Characterizing Data\n"
      ],
      "metadata": {
        "id": "61ahdGHGC4P8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this model, we will be using a toy dataset called Tiny Shakespeare. This dataset contains 40,000 lines of Shakespeare from a variety of his plays. The Tiny Shakespeare dataset has a manageable size, and the complexity of Shakespeare's language."
      ],
      "metadata": {
        "id": "q7hyz7pYKBmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the dataset used for training using the \"web get\" command !wget\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "# Count the number of lines in input.txt - Confirm Number of Lines\n",
        "!wc -l input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UrJnhSQJ1hG",
        "outputId": "5b614e6d-fcd6-4a89-861d-9fe118b87f0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-04 20:27:38--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.5’\n",
            "\n",
            "\rinput.txt.5           0%[                    ]       0  --.-KB/s               \rinput.txt.5         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-04 20:27:38 (28.3 MB/s) - ‘input.txt.5’ saved [1115394/1115394]\n",
            "\n",
            "40000 input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be modeling how these characters follow one another. The transformer model will try to produce character sequences that look like this following the patterns in this data. Once the model is trained, we will generate Shakespeare-like writing. In contrast to ChatGPT, our model will be producing writing on a character-by-character level - whereas ChatGPT produces this in a token-by-token level. Tokens refers to \"sub-word\" pieces."
      ],
      "metadata": {
        "id": "NRhOKwnbNLna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in text as a string in to inspect it\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:                             # open input.txt in read mode, 'r'\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "QcxXVULJJ1ez"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that we are working with ≈ 1M characters:"
      ],
      "metadata": {
        "id": "1DLPqlE3Ts6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quRt5xw8J1ZU",
        "outputId": "23a3ce7b-0652-4343-c926-b7a29d315c01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below,\n",
        "\n",
        "\n",
        "```\n",
        "set(text)                   % contains unique elements (characters) from the \"text\"\n",
        "\n",
        "list(set(text))             % converts the set into a list (preserves order of the elements)\n",
        "\n",
        "sorted(list(set(text)))     % sorts list in ascending order (default)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OL0LKnOEnyC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # here are all the unique characters that occur in this text\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)                                                         # return numer of character elements\n",
        "print(''.join(chars))                                                           # join the characters from 'chars' into a single string without a separator between them, concatenating them into one string\n",
        "print(vocab_size)                                                               # possible elements/characters of our sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBMiJgvrJ1Qb",
        "outputId": "8a9d4f64-d314-4157-8229-1d58d721800e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Tokenizing Input Text"
      ],
      "metadata": {
        "id": "rv9CxKjMrUFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization breaks a stream of data into a meaningful element (words, terms, sentences, symbols, etc). It breaks unstructured data into chunks of discrete elements. In this case, it involves converting the raw text as a string to a sequence of integers according to some vocabulary of possible elements. In our case, we're doing this at the character level because we are creating a character-level model.\n",
        "\n",
        "\n",
        "Reference: https://neptune.ai/blog/tokenization-in-nlp\n",
        "\n",
        "*Personal Note: I think \"encode\" and \"decode\" are poor names for these operations because it can lead to confusion with encoder/decoder in the context of a transformer*\n",
        "\n",
        "Other schemas: Google's SentencePiece (sub-word tokenizer that doesn't encode entire words, but also not only character), OpenAI's tiktoken (bi-pair encoding). Sub-word tokenizers are commonly what's used in practice."
      ],
      "metadata": {
        "id": "95u-bmOIri5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # create a mapping from characters to integers by creating a look up table from character to integer and vice versa\n",
        "\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }                                      # create string to integer dictionary where each unique character, ch, from the 'chars' list is mapped to its corresponding index in the list\n",
        "itos = { i:ch for i,ch in enumerate(chars) }                                      # create integer to string dictionary where each unique index, i, is mapped to its corresponding character, 'ch,' in the 'chars' list\n",
        "encode = lambda s: [stoi[c] for c in s]                                           # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l])                                  # decoder: take a list of integers, output a string\n",
        "\n",
        "# lambda functions are anonymous, one-line functions in the syntax: lambda args: expression\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl9LU3vYpf_m",
        "outputId": "68fd324a-06b5-4aa6-8572-c4c9368d252d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F                                                                  # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# encode(text) converts all of the Shakespeare dataset text from string to integers.\n",
        "# torch.tensor creates a tensor from the list of integers obtained from the encoding. This is a multi-dimensional matrix with elements of a single data type.\n",
        "# torch.long corresponds to 64-bit integers.\n",
        "# reference: https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])                                                               # the first 1000 characters we looked at earlier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuLl_e_hsx4q",
        "outputId": "4aa24906-9d93-4774-86d4-62244b7cc59f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this point, the data is now represented by integers."
      ],
      "metadata": {
        "id": "-QjRxLVW4Irt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Split Data into Train/Test Sets"
      ],
      "metadata": {
        "id": "zIppBtrW4PqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data))                                                          # first 90% will be train, rest val\n",
        "\n",
        "# len(data) >> returns length of the 'data' tensor\n",
        "# 0.9*len(data) >> calculates 90% of the total length of the data. This results in a floating-point value of the index up to the first 90% of the data to be considered for model training\n",
        "# int(0.9*len(data)) >> converts floating-point value to an integer. This rounds down the floating-point value to the nearest integer. This ensures that we can use this as a valud index value.\n",
        "\n",
        "train_data = data[:n]                                                           # first 'n' elements\n",
        "val_data = data[n:]                                                             # last 1-n elements"
      ],
      "metadata": {
        "id": "aBVzVzypsx6u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "YrXo68Oy8eO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d677d8-5b7a-4381-aca7-6d8767e7f009"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1003854"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Loading the Data for Our Model to Use"
      ],
      "metadata": {
        "id": "HERkje436pSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0"
      ],
      "metadata": {
        "id": "Ks5kZuVqwEPP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not going be feeding the entire text to the transformer all at once (too computationally expensive/prohibitive). Therefore, when we train the transformer, we're really only using chunks of the data to do this at a time. These chunks have a max length. This is known as the *block size*. This is in the time dimension of the tensors fed into the transformer."
      ],
      "metadata": {
        "id": "Il1ZTxFX6smN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "id": "8tZcKx_z7EtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7538bdfd-eb2b-4522-aefb-874f67e887f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " In this case, in the context of 18, we see 47 comes next, in the context of 18 and 47, 56 comes next. In the context of 18, 47, 56, then 57 likely comes next, and so on. The purpose of this is to get our transformer used to seeing context as little as 1 to as much as block_size, and everything in between. After block_size, we start truncating because the transformer will never see more than block_size inputs when predicting the next character. This is demonstrated below:"
      ],
      "metadata": {
        "id": "KtVrzZlD9Mp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]                                                      # inputs to the transformer (x block size characters)\n",
        "y = train_data[1:block_size+1]                                                   # starts from the second element up to block size amount characters (these are the targets for each position in the input; the next block size characters). These are our predictions\n",
        "for t in range(block_size):                                                      # loop to iterate \"block_size\" times where the loop variable, 't', takes values from 0 to block_size-1\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "id": "CpDI6t_5sx9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0a4150-df56-45d6-a356-c44bca067623"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) the target: 64\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43]) the target: 52\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]) the target: 10\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10]) the target: 0\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0]) the target: 14\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43]) the target: 44\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44]) the target: 53\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53]) the target: 56\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1]) the target: 61\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1]) the target: 54\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54]) the target: 56\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56]) the target: 53\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53]) the target: 41\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43]) the target: 43\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43]) the target: 42\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42]) the target: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we sample these chunks of text, we're going to have many batches of multiple chunks of text stacked in a single tensor for parallel data processing. These chunks are processed independently and do not communicate with each other. This is the *batch dimension*."
      ],
      "metadata": {
        "id": "Soqjz543Ao2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)                                                           # set random seed for PyTorch's random number generator https://pytorch.org/docs/stable/generated/torch.manual_seed.html\n",
        "                                                               # how many independent sequences will we process in parallel in every forward backward pass in the transformer\n",
        "\n",
        "def get_batch(split):                                                             # create function named 'get_batch' and it takes in a single arg, 'split'\n",
        "\n",
        "    # generates a small batch of data of inputs x and targets y\n",
        "\n",
        "    data = train_data if split == 'train' else val_data                           # selecting the data set to generate batch from. if split arg is 'train,' then train_data set is used, else val_data set is used. this returns our data array\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))                     # determine random positions to grab chunks out of. generate random indices to select the sequences from the data set. number of indices generated equal the 'batch_size' and the indices are chosen randomly within the range of the dataset boundaries. returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive). therefore, this generates batch_size numbers of random offsets, so ix are 4 numbers randomly generated between len(data) - block size. https://pytorch.org/docs/stable/generated/torch.randint.html\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])                           # first block size characters starting at i. construct input tensor, x, by selecting sequences of length of the block size from the dataset based on the random indices ix. this forms the inputs for the batch.\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])                       # constructs ^ for the targets - ^ offset by 1\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y                                                                   # return x and y as a tuple\n",
        "\n",
        "xb, yb = get_batch('train')                                                       # obtains batch of training data\n",
        "print('inputs to trasformer:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size):                                                      # batch dimension\n",
        "    for t in range(block_size):                                                  # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "sNkH0lg6sx_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88dc0fc6-bb28-4352-d0c3-a11d0a0897b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs to trasformer:\n",
            "torch.Size([16, 32])\n",
            "tensor([[58, 53,  1, 41, 53, 56, 56, 59, 54, 58,  1, 39,  1, 51, 39, 52,  5, 57,\n",
            "          1, 61, 47, 44, 43,  1, 47, 57,  0, 61, 46, 43, 52,  1],\n",
            "        [49,  1, 39, 52,  1, 53, 39, 58, 46,  1, 40, 63,  1, 20, 47, 51,  6,  0,\n",
            "         32, 46, 43,  1, 59, 52, 47, 58, 63,  1, 58, 46, 43,  1],\n",
            "        [59, 50, 42,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  1, 57, 53,  1, 58,\n",
            "         53, 53,  2,  0,  0, 24, 33, 15, 21, 27, 10,  0, 35, 43],\n",
            "        [ 8,  0,  0, 35, 13, 30, 35, 21, 15, 23, 10,  0, 28, 56, 53, 60, 43,  1,\n",
            "         47, 58,  6,  1, 20, 43, 52, 56, 63,  6,  1, 39, 52, 42],\n",
            "        [58,  1, 57, 46, 43,  8,  0,  0, 32, 30, 13, 26, 21, 27, 10,  0, 18, 53,\n",
            "         56,  1, 61, 46, 39, 58,  1, 56, 43, 39, 57, 53, 52,  6],\n",
            "        [56, 61, 47, 41, 49,  6,  1, 50, 43, 58,  1, 47, 58,  1, 40, 43, 11,  0,\n",
            "         18, 53, 56,  1, 47, 52,  1, 58, 46, 63,  1, 57, 46, 53],\n",
            "        [25, 10,  0, 35, 47, 58, 46, 42, 56, 39, 61,  1, 63, 53, 59,  1, 46, 43,\n",
            "         52, 41, 43,  6,  1, 51, 63,  1, 50, 53, 56, 42,  6,  1],\n",
            "        [43, 57, 58,  1, 61, 47, 58, 46,  1, 58, 46, 63,  1, 44, 56, 53, 64, 43,\n",
            "         52,  1, 39, 42, 51, 53, 52, 47, 58, 47, 53, 52,  0, 25],\n",
            "        [47, 52, 41, 43,  1, 58, 46, 53, 59,  6,  1, 41, 56, 43, 39, 58, 43, 42,\n",
            "          1, 58, 53,  1, 40, 43,  1, 39, 61, 43, 42,  1, 40, 63],\n",
            "        [53, 52, 57,  8,  0,  0, 34, 27, 24, 33, 25, 26, 21, 13, 10,  0, 27,  6,\n",
            "          1, 52, 53,  1, 51, 53, 56, 43,  6,  1, 52, 53,  1, 51],\n",
            "        [53, 59, 56,  1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58,  8,  1, 18, 53,\n",
            "         56,  1, 58, 46, 43,  1, 42, 43, 39, 56, 58, 46,  6,  0],\n",
            "        [53, 58, 46, 47, 52, 45,  8,  0,  0, 16, 33, 23, 17,  1, 27, 18,  1, 37,\n",
            "         27, 30, 23, 10,  0, 26, 53,  1, 51, 39, 58, 58, 43, 56],\n",
            "        [53, 61,  1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57,  6,  1, 57, 53,\n",
            "         50, 43, 51, 52,  1, 39, 52, 42,  1, 59, 52, 43, 39, 56],\n",
            "        [50, 50,  1, 57, 58, 47, 50, 50,  1, 50, 47, 60, 43,  1, 41, 46, 39, 57,\n",
            "         58, 43, 12,  0,  0, 30, 27, 25, 17, 27, 10,  0, 31, 46],\n",
            "        [21, 21, 10,  0, 13, 63,  6,  1, 47, 44,  1, 63, 53, 59, 56, 57, 43, 50,\n",
            "         44,  5, 57,  1, 56, 43, 51, 43, 51, 40, 56, 39, 52, 41],\n",
            "        [59, 58,  1, 47, 52,  1, 46, 43, 56,  1, 58, 43, 52, 42, 43, 56,  1, 46,\n",
            "         43, 39, 56, 58,  1, 58, 46, 43,  1, 39, 57, 54, 47, 56]])\n",
            "targets:\n",
            "torch.Size([16, 32])\n",
            "tensor([[53,  1, 41, 53, 56, 56, 59, 54, 58,  1, 39,  1, 51, 39, 52,  5, 57,  1,\n",
            "         61, 47, 44, 43,  1, 47, 57,  0, 61, 46, 43, 52,  1, 57],\n",
            "        [ 1, 39, 52,  1, 53, 39, 58, 46,  1, 40, 63,  1, 20, 47, 51,  6,  0, 32,\n",
            "         46, 43,  1, 59, 52, 47, 58, 63,  1, 58, 46, 43,  1, 49],\n",
            "        [50, 42,  1, 58, 46, 53, 59,  1, 61, 43, 56, 58,  1, 57, 53,  1, 58, 53,\n",
            "         53,  2,  0,  0, 24, 33, 15, 21, 27, 10,  0, 35, 43, 50],\n",
            "        [ 0,  0, 35, 13, 30, 35, 21, 15, 23, 10,  0, 28, 56, 53, 60, 43,  1, 47,\n",
            "         58,  6,  1, 20, 43, 52, 56, 63,  6,  1, 39, 52, 42,  1],\n",
            "        [ 1, 57, 46, 43,  8,  0,  0, 32, 30, 13, 26, 21, 27, 10,  0, 18, 53, 56,\n",
            "          1, 61, 46, 39, 58,  1, 56, 43, 39, 57, 53, 52,  6,  1],\n",
            "        [61, 47, 41, 49,  6,  1, 50, 43, 58,  1, 47, 58,  1, 40, 43, 11,  0, 18,\n",
            "         53, 56,  1, 47, 52,  1, 58, 46, 63,  1, 57, 46, 53, 59],\n",
            "        [10,  0, 35, 47, 58, 46, 42, 56, 39, 61,  1, 63, 53, 59,  1, 46, 43, 52,\n",
            "         41, 43,  6,  1, 51, 63,  1, 50, 53, 56, 42,  6,  1, 21],\n",
            "        [57, 58,  1, 61, 47, 58, 46,  1, 58, 46, 63,  1, 44, 56, 53, 64, 43, 52,\n",
            "          1, 39, 42, 51, 53, 52, 47, 58, 47, 53, 52,  0, 25, 39],\n",
            "        [52, 41, 43,  1, 58, 46, 53, 59,  6,  1, 41, 56, 43, 39, 58, 43, 42,  1,\n",
            "         58, 53,  1, 40, 43,  1, 39, 61, 43, 42,  1, 40, 63,  1],\n",
            "        [52, 57,  8,  0,  0, 34, 27, 24, 33, 25, 26, 21, 13, 10,  0, 27,  6,  1,\n",
            "         52, 53,  1, 51, 53, 56, 43,  6,  1, 52, 53,  1, 51, 53],\n",
            "        [59, 56,  1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58,  8,  1, 18, 53, 56,\n",
            "          1, 58, 46, 43,  1, 42, 43, 39, 56, 58, 46,  6,  0, 32],\n",
            "        [58, 46, 47, 52, 45,  8,  0,  0, 16, 33, 23, 17,  1, 27, 18,  1, 37, 27,\n",
            "         30, 23, 10,  0, 26, 53,  1, 51, 39, 58, 58, 43, 56,  6],\n",
            "        [61,  1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57,  6,  1, 57, 53, 50,\n",
            "         43, 51, 52,  1, 39, 52, 42,  1, 59, 52, 43, 39, 56, 58],\n",
            "        [50,  1, 57, 58, 47, 50, 50,  1, 50, 47, 60, 43,  1, 41, 46, 39, 57, 58,\n",
            "         43, 12,  0,  0, 30, 27, 25, 17, 27, 10,  0, 31, 46, 43],\n",
            "        [21, 10,  0, 13, 63,  6,  1, 47, 44,  1, 63, 53, 59, 56, 57, 43, 50, 44,\n",
            "          5, 57,  1, 56, 43, 51, 43, 51, 40, 56, 39, 52, 41, 43],\n",
            "        [58,  1, 47, 52,  1, 46, 43, 56,  1, 58, 43, 52, 42, 43, 56,  1, 46, 43,\n",
            "         39, 56, 58,  1, 58, 46, 43,  1, 39, 57, 54, 47, 56, 47]])\n",
            "----\n",
            "when input is [58] the target: 53\n",
            "when input is [58, 53] the target: 1\n",
            "when input is [58, 53, 1] the target: 41\n",
            "when input is [58, 53, 1, 41] the target: 53\n",
            "when input is [58, 53, 1, 41, 53] the target: 56\n",
            "when input is [58, 53, 1, 41, 53, 56] the target: 56\n",
            "when input is [58, 53, 1, 41, 53, 56, 56] the target: 59\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59] the target: 54\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54] the target: 58\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58] the target: 1\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1] the target: 39\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39] the target: 1\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1] the target: 51\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51] the target: 39\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39] the target: 52\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52] the target: 5\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5] the target: 57\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57] the target: 1\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1] the target: 61\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61] the target: 47\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47] the target: 44\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44] the target: 43\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43] the target: 1\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1] the target: 47\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47] the target: 57\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57] the target: 0\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0] the target: 61\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0, 61] the target: 46\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0, 61, 46] the target: 43\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0, 61, 46, 43] the target: 52\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0, 61, 46, 43, 52] the target: 1\n",
            "when input is [58, 53, 1, 41, 53, 56, 56, 59, 54, 58, 1, 39, 1, 51, 39, 52, 5, 57, 1, 61, 47, 44, 43, 1, 47, 57, 0, 61, 46, 43, 52, 1] the target: 57\n",
            "when input is [49] the target: 1\n",
            "when input is [49, 1] the target: 39\n",
            "when input is [49, 1, 39] the target: 52\n",
            "when input is [49, 1, 39, 52] the target: 1\n",
            "when input is [49, 1, 39, 52, 1] the target: 53\n",
            "when input is [49, 1, 39, 52, 1, 53] the target: 39\n",
            "when input is [49, 1, 39, 52, 1, 53, 39] the target: 58\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58] the target: 46\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46] the target: 1\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1] the target: 40\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40] the target: 63\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63] the target: 1\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1] the target: 20\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20] the target: 47\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47] the target: 51\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51] the target: 6\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6] the target: 0\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0] the target: 32\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32] the target: 46\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46] the target: 43\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43] the target: 1\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1] the target: 59\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59] the target: 52\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52] the target: 47\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47] the target: 58\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58] the target: 63\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63] the target: 1\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63, 1] the target: 58\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63, 1, 58] the target: 46\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63, 1, 58, 46] the target: 43\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63, 1, 58, 46, 43] the target: 1\n",
            "when input is [49, 1, 39, 52, 1, 53, 39, 58, 46, 1, 40, 63, 1, 20, 47, 51, 6, 0, 32, 46, 43, 1, 59, 52, 47, 58, 63, 1, 58, 46, 43, 1] the target: 49\n",
            "when input is [59] the target: 50\n",
            "when input is [59, 50] the target: 42\n",
            "when input is [59, 50, 42] the target: 1\n",
            "when input is [59, 50, 42, 1] the target: 58\n",
            "when input is [59, 50, 42, 1, 58] the target: 46\n",
            "when input is [59, 50, 42, 1, 58, 46] the target: 53\n",
            "when input is [59, 50, 42, 1, 58, 46, 53] the target: 59\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59] the target: 1\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1] the target: 61\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61] the target: 43\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43] the target: 56\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56] the target: 58\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58] the target: 1\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1] the target: 57\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57] the target: 53\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53] the target: 1\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1] the target: 58\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58] the target: 53\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53] the target: 53\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53] the target: 2\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2] the target: 0\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0] the target: 0\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0] the target: 24\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24] the target: 33\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33] the target: 15\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15] the target: 21\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21] the target: 27\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21, 27] the target: 10\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21, 27, 10] the target: 0\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21, 27, 10, 0] the target: 35\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21, 27, 10, 0, 35] the target: 43\n",
            "when input is [59, 50, 42, 1, 58, 46, 53, 59, 1, 61, 43, 56, 58, 1, 57, 53, 1, 58, 53, 53, 2, 0, 0, 24, 33, 15, 21, 27, 10, 0, 35, 43] the target: 50\n",
            "when input is [8] the target: 0\n",
            "when input is [8, 0] the target: 0\n",
            "when input is [8, 0, 0] the target: 35\n",
            "when input is [8, 0, 0, 35] the target: 13\n",
            "when input is [8, 0, 0, 35, 13] the target: 30\n",
            "when input is [8, 0, 0, 35, 13, 30] the target: 35\n",
            "when input is [8, 0, 0, 35, 13, 30, 35] the target: 21\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21] the target: 15\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15] the target: 23\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23] the target: 10\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10] the target: 0\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0] the target: 28\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28] the target: 56\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56] the target: 53\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53] the target: 60\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60] the target: 43\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43] the target: 1\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1] the target: 47\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47] the target: 58\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58] the target: 6\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6] the target: 1\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1] the target: 20\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20] the target: 43\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43] the target: 52\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52] the target: 56\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56] the target: 63\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63] the target: 6\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63, 6] the target: 1\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63, 6, 1] the target: 39\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63, 6, 1, 39] the target: 52\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63, 6, 1, 39, 52] the target: 42\n",
            "when input is [8, 0, 0, 35, 13, 30, 35, 21, 15, 23, 10, 0, 28, 56, 53, 60, 43, 1, 47, 58, 6, 1, 20, 43, 52, 56, 63, 6, 1, 39, 52, 42] the target: 1\n",
            "when input is [58] the target: 1\n",
            "when input is [58, 1] the target: 57\n",
            "when input is [58, 1, 57] the target: 46\n",
            "when input is [58, 1, 57, 46] the target: 43\n",
            "when input is [58, 1, 57, 46, 43] the target: 8\n",
            "when input is [58, 1, 57, 46, 43, 8] the target: 0\n",
            "when input is [58, 1, 57, 46, 43, 8, 0] the target: 0\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0] the target: 32\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32] the target: 30\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30] the target: 13\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13] the target: 26\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26] the target: 21\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21] the target: 27\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27] the target: 10\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10] the target: 0\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0] the target: 18\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18] the target: 53\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53] the target: 56\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56] the target: 1\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1] the target: 61\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61] the target: 46\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46] the target: 39\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39] the target: 58\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58] the target: 1\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1] the target: 56\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56] the target: 43\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43] the target: 39\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43, 39] the target: 57\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43, 39, 57] the target: 53\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43, 39, 57, 53] the target: 52\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43, 39, 57, 53, 52] the target: 6\n",
            "when input is [58, 1, 57, 46, 43, 8, 0, 0, 32, 30, 13, 26, 21, 27, 10, 0, 18, 53, 56, 1, 61, 46, 39, 58, 1, 56, 43, 39, 57, 53, 52, 6] the target: 1\n",
            "when input is [56] the target: 61\n",
            "when input is [56, 61] the target: 47\n",
            "when input is [56, 61, 47] the target: 41\n",
            "when input is [56, 61, 47, 41] the target: 49\n",
            "when input is [56, 61, 47, 41, 49] the target: 6\n",
            "when input is [56, 61, 47, 41, 49, 6] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1] the target: 50\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50] the target: 43\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43] the target: 58\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1] the target: 47\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47] the target: 58\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1] the target: 40\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40] the target: 43\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43] the target: 11\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11] the target: 0\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0] the target: 18\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18] the target: 53\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53] the target: 56\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1] the target: 47\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47] the target: 52\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1] the target: 58\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58] the target: 46\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46] the target: 63\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46, 63] the target: 1\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46, 63, 1] the target: 57\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46, 63, 1, 57] the target: 46\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46, 63, 1, 57, 46] the target: 53\n",
            "when input is [56, 61, 47, 41, 49, 6, 1, 50, 43, 58, 1, 47, 58, 1, 40, 43, 11, 0, 18, 53, 56, 1, 47, 52, 1, 58, 46, 63, 1, 57, 46, 53] the target: 59\n",
            "when input is [25] the target: 10\n",
            "when input is [25, 10] the target: 0\n",
            "when input is [25, 10, 0] the target: 35\n",
            "when input is [25, 10, 0, 35] the target: 47\n",
            "when input is [25, 10, 0, 35, 47] the target: 58\n",
            "when input is [25, 10, 0, 35, 47, 58] the target: 46\n",
            "when input is [25, 10, 0, 35, 47, 58, 46] the target: 42\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42] the target: 56\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56] the target: 39\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39] the target: 61\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61] the target: 1\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1] the target: 63\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63] the target: 53\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53] the target: 59\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59] the target: 1\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1] the target: 46\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46] the target: 43\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43] the target: 52\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52] the target: 41\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41] the target: 43\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43] the target: 6\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6] the target: 1\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1] the target: 51\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51] the target: 63\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63] the target: 1\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1] the target: 50\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50] the target: 53\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50, 53] the target: 56\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50, 53, 56] the target: 42\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50, 53, 56, 42] the target: 6\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50, 53, 56, 42, 6] the target: 1\n",
            "when input is [25, 10, 0, 35, 47, 58, 46, 42, 56, 39, 61, 1, 63, 53, 59, 1, 46, 43, 52, 41, 43, 6, 1, 51, 63, 1, 50, 53, 56, 42, 6, 1] the target: 21\n",
            "when input is [43] the target: 57\n",
            "when input is [43, 57] the target: 58\n",
            "when input is [43, 57, 58] the target: 1\n",
            "when input is [43, 57, 58, 1] the target: 61\n",
            "when input is [43, 57, 58, 1, 61] the target: 47\n",
            "when input is [43, 57, 58, 1, 61, 47] the target: 58\n",
            "when input is [43, 57, 58, 1, 61, 47, 58] the target: 46\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46] the target: 1\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1] the target: 58\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58] the target: 46\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46] the target: 63\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63] the target: 1\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1] the target: 44\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44] the target: 56\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56] the target: 53\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53] the target: 64\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64] the target: 43\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43] the target: 52\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52] the target: 1\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1] the target: 39\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39] the target: 42\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42] the target: 51\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51] the target: 53\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53] the target: 52\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52] the target: 47\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47] the target: 58\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58] the target: 47\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58, 47] the target: 53\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58, 47, 53] the target: 52\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58, 47, 53, 52] the target: 0\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58, 47, 53, 52, 0] the target: 25\n",
            "when input is [43, 57, 58, 1, 61, 47, 58, 46, 1, 58, 46, 63, 1, 44, 56, 53, 64, 43, 52, 1, 39, 42, 51, 53, 52, 47, 58, 47, 53, 52, 0, 25] the target: 39\n",
            "when input is [47] the target: 52\n",
            "when input is [47, 52] the target: 41\n",
            "when input is [47, 52, 41] the target: 43\n",
            "when input is [47, 52, 41, 43] the target: 1\n",
            "when input is [47, 52, 41, 43, 1] the target: 58\n",
            "when input is [47, 52, 41, 43, 1, 58] the target: 46\n",
            "when input is [47, 52, 41, 43, 1, 58, 46] the target: 53\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53] the target: 59\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59] the target: 6\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6] the target: 1\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1] the target: 41\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41] the target: 56\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56] the target: 43\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43] the target: 39\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39] the target: 58\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58] the target: 43\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43] the target: 42\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42] the target: 1\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1] the target: 58\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58] the target: 53\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53] the target: 1\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1] the target: 40\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40] the target: 43\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43] the target: 1\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1] the target: 39\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39] the target: 61\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61] the target: 43\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61, 43] the target: 42\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61, 43, 42] the target: 1\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61, 43, 42, 1] the target: 40\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61, 43, 42, 1, 40] the target: 63\n",
            "when input is [47, 52, 41, 43, 1, 58, 46, 53, 59, 6, 1, 41, 56, 43, 39, 58, 43, 42, 1, 58, 53, 1, 40, 43, 1, 39, 61, 43, 42, 1, 40, 63] the target: 1\n",
            "when input is [53] the target: 52\n",
            "when input is [53, 52] the target: 57\n",
            "when input is [53, 52, 57] the target: 8\n",
            "when input is [53, 52, 57, 8] the target: 0\n",
            "when input is [53, 52, 57, 8, 0] the target: 0\n",
            "when input is [53, 52, 57, 8, 0, 0] the target: 34\n",
            "when input is [53, 52, 57, 8, 0, 0, 34] the target: 27\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27] the target: 24\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24] the target: 33\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33] the target: 25\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25] the target: 26\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26] the target: 21\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21] the target: 13\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13] the target: 10\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10] the target: 0\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0] the target: 27\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27] the target: 6\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6] the target: 1\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1] the target: 52\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52] the target: 53\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53] the target: 1\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1] the target: 51\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51] the target: 53\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53] the target: 56\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56] the target: 43\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43] the target: 6\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6] the target: 1\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6, 1] the target: 52\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6, 1, 52] the target: 53\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6, 1, 52, 53] the target: 1\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6, 1, 52, 53, 1] the target: 51\n",
            "when input is [53, 52, 57, 8, 0, 0, 34, 27, 24, 33, 25, 26, 21, 13, 10, 0, 27, 6, 1, 52, 53, 1, 51, 53, 56, 43, 6, 1, 52, 53, 1, 51] the target: 53\n",
            "when input is [53] the target: 59\n",
            "when input is [53, 59] the target: 56\n",
            "when input is [53, 59, 56] the target: 1\n",
            "when input is [53, 59, 56, 1] the target: 47\n",
            "when input is [53, 59, 56, 1, 47] the target: 51\n",
            "when input is [53, 59, 56, 1, 47, 51] the target: 54\n",
            "when input is [53, 59, 56, 1, 47, 51, 54] the target: 43\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43] the target: 42\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42] the target: 47\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47] the target: 51\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51] the target: 43\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43] the target: 52\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52] the target: 58\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58] the target: 8\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8] the target: 1\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1] the target: 18\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18] the target: 53\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53] the target: 56\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56] the target: 1\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1] the target: 58\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58] the target: 46\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46] the target: 43\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43] the target: 1\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1] the target: 42\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42] the target: 43\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43] the target: 39\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39] the target: 56\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39, 56] the target: 58\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39, 56, 58] the target: 46\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39, 56, 58, 46] the target: 6\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39, 56, 58, 46, 6] the target: 0\n",
            "when input is [53, 59, 56, 1, 47, 51, 54, 43, 42, 47, 51, 43, 52, 58, 8, 1, 18, 53, 56, 1, 58, 46, 43, 1, 42, 43, 39, 56, 58, 46, 6, 0] the target: 32\n",
            "when input is [53] the target: 58\n",
            "when input is [53, 58] the target: 46\n",
            "when input is [53, 58, 46] the target: 47\n",
            "when input is [53, 58, 46, 47] the target: 52\n",
            "when input is [53, 58, 46, 47, 52] the target: 45\n",
            "when input is [53, 58, 46, 47, 52, 45] the target: 8\n",
            "when input is [53, 58, 46, 47, 52, 45, 8] the target: 0\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0] the target: 0\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0] the target: 16\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16] the target: 33\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33] the target: 23\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23] the target: 17\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17] the target: 1\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1] the target: 27\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27] the target: 18\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18] the target: 1\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1] the target: 37\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37] the target: 27\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27] the target: 30\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30] the target: 23\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23] the target: 10\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10] the target: 0\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0] the target: 26\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26] the target: 53\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53] the target: 1\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1] the target: 51\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51] the target: 39\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51, 39] the target: 58\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51, 39, 58] the target: 58\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51, 39, 58, 58] the target: 43\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51, 39, 58, 58, 43] the target: 56\n",
            "when input is [53, 58, 46, 47, 52, 45, 8, 0, 0, 16, 33, 23, 17, 1, 27, 18, 1, 37, 27, 30, 23, 10, 0, 26, 53, 1, 51, 39, 58, 58, 43, 56] the target: 6\n",
            "when input is [53] the target: 61\n",
            "when input is [53, 61] the target: 1\n",
            "when input is [53, 61, 1] the target: 41\n",
            "when input is [53, 61, 1, 41] the target: 43\n",
            "when input is [53, 61, 1, 41, 43] the target: 56\n",
            "when input is [53, 61, 1, 41, 43, 56] the target: 43\n",
            "when input is [53, 61, 1, 41, 43, 56, 43] the target: 51\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51] the target: 53\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53] the target: 52\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52] the target: 47\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47] the target: 53\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53] the target: 59\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59] the target: 57\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57] the target: 6\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6] the target: 1\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1] the target: 57\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57] the target: 53\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53] the target: 50\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50] the target: 43\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43] the target: 51\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51] the target: 52\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52] the target: 1\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1] the target: 39\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39] the target: 52\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52] the target: 42\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42] the target: 1\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1] the target: 59\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1, 59] the target: 52\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1, 59, 52] the target: 43\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1, 59, 52, 43] the target: 39\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1, 59, 52, 43, 39] the target: 56\n",
            "when input is [53, 61, 1, 41, 43, 56, 43, 51, 53, 52, 47, 53, 59, 57, 6, 1, 57, 53, 50, 43, 51, 52, 1, 39, 52, 42, 1, 59, 52, 43, 39, 56] the target: 58\n",
            "when input is [50] the target: 50\n",
            "when input is [50, 50] the target: 1\n",
            "when input is [50, 50, 1] the target: 57\n",
            "when input is [50, 50, 1, 57] the target: 58\n",
            "when input is [50, 50, 1, 57, 58] the target: 47\n",
            "when input is [50, 50, 1, 57, 58, 47] the target: 50\n",
            "when input is [50, 50, 1, 57, 58, 47, 50] the target: 50\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50] the target: 1\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1] the target: 50\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50] the target: 47\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47] the target: 60\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60] the target: 43\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43] the target: 1\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1] the target: 41\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41] the target: 46\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46] the target: 39\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39] the target: 57\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57] the target: 58\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58] the target: 43\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43] the target: 12\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12] the target: 0\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0] the target: 0\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0] the target: 30\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30] the target: 27\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27] the target: 25\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25] the target: 17\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17] the target: 27\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17, 27] the target: 10\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17, 27, 10] the target: 0\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17, 27, 10, 0] the target: 31\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17, 27, 10, 0, 31] the target: 46\n",
            "when input is [50, 50, 1, 57, 58, 47, 50, 50, 1, 50, 47, 60, 43, 1, 41, 46, 39, 57, 58, 43, 12, 0, 0, 30, 27, 25, 17, 27, 10, 0, 31, 46] the target: 43\n",
            "when input is [21] the target: 21\n",
            "when input is [21, 21] the target: 10\n",
            "when input is [21, 21, 10] the target: 0\n",
            "when input is [21, 21, 10, 0] the target: 13\n",
            "when input is [21, 21, 10, 0, 13] the target: 63\n",
            "when input is [21, 21, 10, 0, 13, 63] the target: 6\n",
            "when input is [21, 21, 10, 0, 13, 63, 6] the target: 1\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1] the target: 47\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47] the target: 44\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44] the target: 1\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1] the target: 63\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63] the target: 53\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53] the target: 59\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59] the target: 56\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56] the target: 57\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57] the target: 43\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43] the target: 50\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50] the target: 44\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44] the target: 5\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5] the target: 57\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57] the target: 1\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1] the target: 56\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56] the target: 43\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43] the target: 51\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51] the target: 43\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43] the target: 51\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51] the target: 40\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51, 40] the target: 56\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51, 40, 56] the target: 39\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51, 40, 56, 39] the target: 52\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51, 40, 56, 39, 52] the target: 41\n",
            "when input is [21, 21, 10, 0, 13, 63, 6, 1, 47, 44, 1, 63, 53, 59, 56, 57, 43, 50, 44, 5, 57, 1, 56, 43, 51, 43, 51, 40, 56, 39, 52, 41] the target: 43\n",
            "when input is [59] the target: 58\n",
            "when input is [59, 58] the target: 1\n",
            "when input is [59, 58, 1] the target: 47\n",
            "when input is [59, 58, 1, 47] the target: 52\n",
            "when input is [59, 58, 1, 47, 52] the target: 1\n",
            "when input is [59, 58, 1, 47, 52, 1] the target: 46\n",
            "when input is [59, 58, 1, 47, 52, 1, 46] the target: 43\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43] the target: 56\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56] the target: 1\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1] the target: 58\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58] the target: 43\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43] the target: 52\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52] the target: 42\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42] the target: 43\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43] the target: 56\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56] the target: 1\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1] the target: 46\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46] the target: 43\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43] the target: 39\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39] the target: 56\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56] the target: 58\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58] the target: 1\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1] the target: 58\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58] the target: 46\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46] the target: 43\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43] the target: 1\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1] the target: 39\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1, 39] the target: 57\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1, 39, 57] the target: 54\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1, 39, 57, 54] the target: 47\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1, 39, 57, 54, 47] the target: 56\n",
            "when input is [59, 58, 1, 47, 52, 1, 46, 43, 56, 1, 58, 43, 52, 42, 43, 56, 1, 46, 43, 39, 56, 58, 1, 58, 46, 43, 1, 39, 57, 54, 47, 56] the target: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "NvOYjYblxBpr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 4 × 8 array above would give us 32 examples (gives us cases where we can say \"when the input is #, the target is #; when the input is #, #, the target is #). They're completely independent as far as transformer is concerned. These are 32 indepedent examples packed into a single batch. This integer tensor of x will feed into the transformer, and it will simultaneously process all these examples."
      ],
      "metadata": {
        "id": "31ol4vF_K672"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Training the Transformer Model"
      ],
      "metadata": {
        "id": "76lQBensL61Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: *The simple bigram model will not perform well because the tokens are NOT talking to each other. This is where the transformer will help.*"
      ],
      "metadata": {
        "id": "0u_C4O8VSf0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Bigram Model Class"
      ],
      "metadata": {
        "id": "2tQdICbK3A5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by building a bigram model - one of the simplest neural networks.\n",
        "\n",
        "For more information on bigram model: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#:~:text=A%20bigram%20language%20model%20is,in%20a%20text%20or%20sentence."
      ],
      "metadata": {
        "id": "rr-B2WYXBsbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a classification ML task, cross-entropy loss (aka log loss or softmax loss) is the employed loss function. This is the difference between the projected probability distribution and the actual proability distribution of the target classes. In this case, we have ID of next character so this evaluates quality of prediction wrt to target. Correct dim of logits should yield high value, and other dims low. Because we have 65 possible vocabulary elements, we can guess loss as: $-ln(1/65)=4.17$\n",
        "\n",
        "See more: https://www.educative.io/answers/what-is-cross-entropy-loss-in-pytorch.\n",
        "\n",
        "Lecture 28 ML"
      ],
      "metadata": {
        "id": "sVeJflrQgncl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax Function: Turns vector of K real values into a vector of K real values that sum to 1. The inputs can be +, , 0, or greater than 1 but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities. See more: https://deepai.org/machine-learning-glossary-and-terms/softmax-layer#:~:text=The%20softmax%20function%20is%20a,can%20be%20interpreted%20as%20probabilities.\n",
        "\n",
        "\n",
        "Softmax($x_i$) = $\\frac{e^{x_i}}{∑_j e^{x_j}}$"
      ],
      "metadata": {
        "id": "V44Oo9g_kz-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "FXRJOYwLvu50"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "TFgtNj7xvu2t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "6rJ3Y2m7vuva"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MrqtsKuFvulR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):                                             # using nn.Module enables us to use PyTorch's neural network capabilities; this is the base for all neural network models https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)         # create embedding table to map token indices to corresponding embedding vector https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html. Arg: vocab_size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "\n",
        "    # predicting what comes next based on previous token only\n",
        "    def forward(self, idx, targets=None):                                         # this method must be implemented under \"nn.Module\" and it defines how input data is processed through the network (incl activation functions, transformations, etc).\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)                                # (B: batch, T: tokens, C: classes); retrieve embedding vectors. logits = scores\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:                                                                     # if targets are provided the cross-entropy loss between the predicted logits and the actual targets is computed; otherwise the loss is none\n",
        "            B, T, C = logits.shape                                                # define as idx to match cross-entropy function expected input\n",
        "            # reshaping to match cross entropy function inputs\n",
        "            logits = logits.view(B*T, C)                                          # convert to a 2D tensor [row: logits for specific token in the batch for all time steps, col: logits for the different classes (in this case vocab_size, which is 65)]\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)                               # https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
        "\n",
        "        return logits, loss                                                       # logist = raw score\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):                                           # predict the new tokens based on the context of the previous token; note to self: '_' can be used when variable name is not relevant within the loop\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]                                             # becomes (B, C) ; the -1 represents the selection o the last element along this dim (the sequence length)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)                                     # (B, C); applying the softmax function to the logits (ensure they sum to 1 along the classes dimension) https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)                    # (B, 1); draw one sample for each probability distribution https://pytorch.org/docs/stable/generated/torch.multinomial.html\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)                    # concatenates tensor\n",
        "        return idx\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWa0iXNYsyBv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHDP7wcjxXXV",
        "outputId": "766a391b-ad2b-40ff-c7bd-3f32ae94a5d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "cJsJbnmIydnH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2Px7dSydkw",
        "outputId": "e9a8bb8d-0451-42e2-d7f0-67e29a04277d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.4049, val loss 4.3996\n",
            "step 100: train loss 2.6715, val loss 2.6830\n",
            "step 200: train loss 2.5027, val loss 2.4981\n",
            "step 300: train loss 2.4163, val loss 2.4299\n",
            "step 400: train loss 2.3453, val loss 2.3580\n",
            "step 500: train loss 2.3025, val loss 2.3216\n",
            "step 600: train loss 2.2374, val loss 2.2534\n",
            "step 700: train loss 2.2067, val loss 2.2190\n",
            "step 800: train loss 2.1565, val loss 2.1788\n",
            "step 900: train loss 2.1162, val loss 2.1491\n",
            "step 1000: train loss 2.0877, val loss 2.1191\n",
            "step 1100: train loss 2.0555, val loss 2.1081\n",
            "step 1200: train loss 2.0215, val loss 2.0705\n",
            "step 1300: train loss 2.0099, val loss 2.0499\n",
            "step 1400: train loss 1.9754, val loss 2.0217\n",
            "step 1500: train loss 1.9512, val loss 2.0187\n",
            "step 1600: train loss 1.9321, val loss 2.0204\n",
            "step 1700: train loss 1.9278, val loss 2.0058\n",
            "step 1800: train loss 1.8854, val loss 1.9831\n",
            "step 1900: train loss 1.8746, val loss 1.9619\n",
            "step 2000: train loss 1.8637, val loss 1.9739\n",
            "step 2100: train loss 1.8482, val loss 1.9534\n",
            "step 2200: train loss 1.8319, val loss 1.9380\n",
            "step 2300: train loss 1.8246, val loss 1.9333\n",
            "step 2400: train loss 1.8103, val loss 1.9073\n",
            "step 2500: train loss 1.7911, val loss 1.9243\n",
            "step 2600: train loss 1.7948, val loss 1.9194\n",
            "step 2700: train loss 1.7888, val loss 1.9154\n",
            "step 2800: train loss 1.7743, val loss 1.8978\n",
            "step 2900: train loss 1.7711, val loss 1.9025\n",
            "step 3000: train loss 1.7646, val loss 1.8907\n",
            "step 3100: train loss 1.7446, val loss 1.8986\n",
            "step 3200: train loss 1.7276, val loss 1.8784\n",
            "step 3300: train loss 1.7334, val loss 1.8825\n",
            "step 3400: train loss 1.7279, val loss 1.8693\n",
            "step 3500: train loss 1.7110, val loss 1.8663\n",
            "step 3600: train loss 1.7005, val loss 1.8684\n",
            "step 3700: train loss 1.7044, val loss 1.8601\n",
            "step 3800: train loss 1.6989, val loss 1.8705\n",
            "step 3900: train loss 1.6961, val loss 1.8445\n",
            "step 4000: train loss 1.6833, val loss 1.8336\n",
            "step 4100: train loss 1.6857, val loss 1.8434\n",
            "step 4200: train loss 1.6847, val loss 1.8468\n",
            "step 4300: train loss 1.6801, val loss 1.8244\n",
            "step 4400: train loss 1.6829, val loss 1.8370\n",
            "step 4500: train loss 1.6691, val loss 1.8268\n",
            "step 4600: train loss 1.6624, val loss 1.8113\n",
            "step 4700: train loss 1.6585, val loss 1.8107\n",
            "step 4800: train loss 1.6453, val loss 1.8212\n",
            "step 4900: train loss 1.6477, val loss 1.8181\n",
            "step 4999: train loss 1.6437, val loss 1.8108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKf1MWULydi6",
        "outputId": "7c6123d7-97aa-4a15-ff55-472c9bdf24b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "And farmen:\n",
            "Therefore us; come hard It Dome,\n",
            "This to our sweet might, or that must springs to but too?\n",
            "\n",
            "First Lord, Parge to, thyse Is bland,\n",
            "se thou companish he thus mind; his by betwereignt, tho, guines do rith.\n",
            "\n",
            "KING EDWARD IV:\n",
            "What shall your sI a hard,---love.\n",
            "\n",
            "POLIXENES:\n",
            "Why, with the will be as\n",
            "by thou sover conurse\n",
            "Wetwould pity.\n",
            "\n",
            "KING RICHARD II:\n",
            "gold,\n",
            "Thuntle of you, was me; an your tought\n",
            "Of najeckingling to-does, and little spright.\n",
            "\n",
            "GLOUCESTER:\n",
            "Roman made; I godve his is brother be slory.\n",
            "Nay! if the stable:\n",
            "Of where as suses, passes us.\n",
            "\n",
            "LUCENTIO:\n",
            "He ratherefords throw and praader?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Offights thou love the confert late a with thy self,\n",
            "Ofly us beltragin mady kingmand Her foul his foll busine.\n",
            "Proker, prinried Andlescupingrate:\n",
            "By for my sick? Io, was myself!\n",
            "\n",
            "Secragespet the gatious I'll:\n",
            "The conching-sconcears at and havelget\n",
            "well bear confath with me. Him you, profired take\n",
            "Apase, names bonul straving yonger's cleave\n",
            "Will him Rivisted in his slope.\n",
            "\n",
            "Bentice was suilton onj you the would the farther,\n",
            "And than wark you, baut, I us orlild.\n",
            "\n",
            "KING RICHARD II:\n",
            "My do threan advost thy force have he,\n",
            "whith they worn with the measure? what you, I vostity.\n",
            "Why, that, our stoly cannary own!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Do statts! of the hungring.\n",
            "\n",
            "Nurse:\n",
            "There shese; Ged.\n",
            "Made, thou thy lamp, on your,\n",
            "And grackly his name the cronget well\n",
            "in him. But:\n",
            "In I surn of shall! I play whole not sumpeted\n",
            "To night the rese: is brive, he geltion and to\n",
            "Ever his sabiand.\n",
            "But, pleaguy sorrow lomes and noble.\n",
            "\n",
            "KING RICHARD:\n",
            "From foll your made; It rese, and peopnenet stresd makings!\n",
            "\n",
            "POLIXENCE:\n",
            "Stasting, that bristloty.\n",
            "\n",
            "HENRY VI:\n",
            "As fitther Is o' a purpurpt.\n",
            "\n",
            "First Nurity;\n",
            "And underther, suilt with requmand,\n",
            "up I' answilte firs unfeed them.\n",
            "If that be? forthing in myself my powaint.\n",
            "You will. If seee them thou\n",
            "the flass that him. Pray youthful brievent throads my widitledy,\n",
            "Hinking from it to reporthing on the bo's and clighty\n",
            "Con to surreignneds off the it, bratterefo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we can evaluate the quality of the model from the loss value. In this case, the loss value is higher than our \"guess,\" meaning our predictions are a bit more diffuse."
      ],
      "metadata": {
        "id": "rhkRebH6xltO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting an Optimizer"
      ],
      "metadata": {
        "id": "NWE3V1nE2use"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, we want to update the learning rate so that we can perform reasonable updates. Adam (adaptive moment estimation) is a standard optimization learning algo for training DNNs."
      ],
      "metadata": {
        "id": "Gl28vJD23M6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "XinV8nmAnmKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ],
      "metadata": {
        "id": "M5CvobiQ0pLr"
      }
    }
  ]
}