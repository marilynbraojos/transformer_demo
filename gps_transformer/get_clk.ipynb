{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c9c05d-936a-4baa-949e-72deea387a40",
   "metadata": {},
   "source": [
    "**This program is complete**\n",
    "\n",
    "**Author:** Marilyn Braojos \n",
    "\n",
    "**Purpose:** This program aims to connect to the CDDIS servers to obtain GPS final clock products. It is separated into 3 main parts: \n",
    "\n",
    "* Connecting to CDDIS servers\n",
    "* Downloading data for a given GPS week\n",
    "* Saving data for that week as an npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a2dc2-8e8c-4d08-a044-0b765bf0c73e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d95cfd-a3cf-46ac-bcb2-8adc8f853663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP_TLS\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from unlzw import unlzw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec18f9-beaf-4e87-9647-663f6d63ba77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# FTP Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca82e7-9488-43e7-a145-a07bbd90be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"gdc.cddis.eosdis.nasa.gov\"\n",
    "port = 21  # passive mode\n",
    "username = \"anonymous\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df77bb-4454-4d92-b36e-87f0079fdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = FTP_TLS()\n",
    "ftp.connect(host, port)\n",
    "ftp.login(username, password)\n",
    "ftp.prot_p()\n",
    "ftp.retrlines('LIST') # list files in server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b7957-7692-4f28-8421-15c03df8fcc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Download and Save Data Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04163bde-35fb-4deb-b9a1-f8570b29e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(week):\n",
    "        try:\n",
    "            base_dir = '/pub/gps/products'\n",
    "            ftp.cwd(base_dir)\n",
    "            \n",
    "            week_folder = f\"{week}\"\n",
    "            ftp.cwd(week_folder)\n",
    "        \n",
    "            # List all files in the directory\n",
    "            \n",
    "            files = []\n",
    "            ftp.retrlines('NLST', files.append)\n",
    "    \n",
    "            clk_files = [file for file in files if file.endswith('.CLK.gz')] # CLK is case-sensitive\n",
    "            \n",
    "            data_dir = 'clk'\n",
    "            new_folder = os.path.join(data_dir, f'gps_{week}')\n",
    "            os.makedirs(new_folder, exist_ok=True)\n",
    "    \n",
    "            for i, clk_file in enumerate(clk_files):\n",
    "                local_filename = os.path.join(new_folder, clk_file)\n",
    "                \n",
    "                with open(local_filename, 'wb') as f:\n",
    "                    ftp.retrbinary(f\"RETR {clk_file}\", f.write)\n",
    "\n",
    "                if clk_file.endswith('.gz'):\n",
    "                    local_uncompressed = local_filename[:-3]\n",
    "                    try: \n",
    "                        with gzip.open(local_filename, 'rb') as gzipped_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                            decompressed_file.write(gzipped_file.read())\n",
    "                            files.append(local_uncompressed)\n",
    "                    except Exception as e: \n",
    "                        print(f\"Error uncompressing file {local_filename}: {e}. Will begin uncompressing file as a UNIX compressed file\")\n",
    "                        with open(local_filename, 'rb') as compressed_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                            decompressed_file.write(unlzw(compressed_file.read()))\n",
    "                            files.append(local_uncompressed)\n",
    "                            print(f\"Successfully uncompressed and saved file {local_filename} as a UNIX compressed file\")\n",
    "                            \n",
    "                print(f\"Done saving file {i + 1} out of {len(clk_files)} for week: {week}\")\n",
    "            print(f\"Done uncompressing and saving files for week: {week}\")      \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for week {week}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4744770-0f64-44ba-a2a6-a066464a5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "fetch_data(2035)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8407e-ad3e-4a03-9db4-cad6dacb20f9",
   "metadata": {},
   "source": [
    "# Navigate to IGS Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d6c63-620d-4cc7-beda-a536eabf5772",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebdff2d7-58c2-4d22-924f-7c0bf920552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_clk(week):\n",
    "    try:\n",
    "        base_dir = 'clk'        \n",
    "        week_folder = f\"gps_{week}\"\n",
    "        target_dir = os.path.join(base_dir, week_folder)\n",
    "\n",
    "        if not os.path.isdir(target_dir):\n",
    "            raise FileNotFoundError(f\"Directory {target_dir} does not exist.\")\n",
    "\n",
    "\n",
    "        clk_files = [file for file in os.listdir(target_dir) if file.endswith('.CLK')] # CLK is case-sensitive\n",
    "\n",
    "        data = []\n",
    "        line_ct = 0\n",
    "\n",
    "        for i, clk_file in enumerate(clk_files):\n",
    "            file_path = os.path.join(target_dir, clk_file) \n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                first_line = file.readline()\n",
    "                \n",
    "                is_version_3 = False\n",
    "                is_not_version_3 = False\n",
    "                end_header = False\n",
    "\n",
    "                if '3.04' in first_line[0:21]: \n",
    "                    is_version_3 = True\n",
    "                else:\n",
    "                    is_not_version_3 = True\n",
    "                \n",
    "                for line in file:\n",
    "                                        \n",
    "                    if not end_header:\n",
    "                        if 'END OF HEADER' in line:\n",
    "                            end_header = True\n",
    "                        continue\n",
    "                    \n",
    "                    if line.startswith('AS'):\n",
    "                        if end_header: \n",
    "                            if is_version_3:   \n",
    "                                if line[3:13].startswith('G'):\n",
    "                           \n",
    "                                    row = {\n",
    "                                        'Clock Data Type': line[0:3],\n",
    "                                        'SV Name': line[3:13],\n",
    "                                        'Epoch Year': int(line[13:18]),\n",
    "                                        'Epoch Month': int(line[18:21]),\n",
    "                                        'Epoch Day': int(line[21:24]),\n",
    "                                        'Epoch Hour': int(line[24:27]),\n",
    "                                        'Epoch Minute': int(line[27:30]),\n",
    "                                        'Epoch Second': int(float(line[30:40])),\n",
    "                                        'Number of Data Values to Follow': int(line[40:45]),\n",
    "                                        'Clock Bias (seconds)': float(line[45:66].lower().replace('d', 'e')),\n",
    "                                        'Version': \"Version 3.04\",\n",
    "                                        'File': file_path,\n",
    "                                                    # 'Clock Bias StdDev (seconds)': clock_bias_stddev,\n",
    "                                                    # 'Clock Rate (dimensionless)': clock_rate,\n",
    "                                                    # 'Clock Rate StdDev (dimensionless)': clock_rate_stddev,\n",
    "                                                    # 'Clock Acceleration (per second)': clock_acceleration,\n",
    "                                                    # 'Clock Acceleration StdDev (per second)': clock_acceleration_stddev,\n",
    "                                                    }\n",
    "                                    data.append(row)\n",
    "    \n",
    "                            # https://files.igs.org/pub/data/format/rinex_clock300.txt\n",
    "                            elif is_not_version_3:   \n",
    "                                if line[3:8].startswith('G'):\n",
    "                  \n",
    "                                    row = {\n",
    "                                        'Clock Data Type': line[0:3],\n",
    "                                        'SV Name': line[3:8],\n",
    "                                        'Epoch Year': int(line[8:12]),\n",
    "                                        'Epoch Month': int(line[12:15]),\n",
    "                                        'Epoch Day': int(line[15:18]),\n",
    "                                        'Epoch Hour': int(line[18:21]),\n",
    "                                        'Epoch Minute': int(line[21:24]),\n",
    "                                        'Epoch Second': int(float(line[24:34])),\n",
    "                                        'Number of Data Values to Follow': int(line[34:40]),\n",
    "                                        'Clock Bias (seconds)': float(line[40:59].lower().replace('d', 'e')),\n",
    "                                        'Version': \"NOT version 3.04\" ,\n",
    "                                        'File': file_path,\n",
    "                                                    # 'Clock Bias StdDev (seconds)': clock_bias_stddev,\n",
    "                                                    # 'Clock Rate (dimensionless)': clock_rate,\n",
    "                                                    # 'Clock Rate StdDev (dimensionless)': clock_rate_stddev,\n",
    "                                                    # 'Clock Acceleration (per second)': clock_acceleration,\n",
    "                                                    # 'Clock Acceleration StdDev (per second)': clock_acceleration_stddev,\n",
    "                                                    }\n",
    "                                    data.append(row)\n",
    "\n",
    "            print(f\"Done reading file {i + 1} out of {len(clk_files)}\")\n",
    "        \n",
    "        sv_names = [entry['SV Name'] for entry in data]\n",
    "        print(f\"SV Names for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_years = [entry['Epoch Year'] for entry in data]\n",
    "        print(f\"Epoch Years for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_months = [entry['Epoch Month'] for entry in data]\n",
    "        print(f\"Epoch Months for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_days = [entry['Epoch Day'] for entry in data]\n",
    "        print(f\"Epoch Days for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_hours = [entry['Epoch Hour'] for entry in data]\n",
    "        print(f\"Epoch Hours for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_minutes = [entry['Epoch Minute'] for entry in data]\n",
    "        print(f\"Epoch Minutes for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_seconds = [entry['Epoch Second'] for entry in data]\n",
    "        print(f\"Epoch Seconds for GPS week {week} have been saved.\")\n",
    "        \n",
    "        clock_biases = [entry['Clock Bias (seconds)'] for entry in data]\n",
    "        print(f\"Clock biases (seconds) for GPS week {week} have been saved.\")\n",
    "\n",
    "        ver_names = [entry['Version'] for entry in data]\n",
    "        print(f\"Versions for GPS week {week} have been saved.\")\n",
    "\n",
    "        file_names = [entry['File'] for entry in data]\n",
    "        print(f\"Filepaths for GPS week {week} have been saved.\")\n",
    "\n",
    "        combined = list(zip(sv_names,\n",
    "                            epoch_years,\n",
    "                            epoch_months,\n",
    "                            epoch_days,\n",
    "                            epoch_hours,\n",
    "                            epoch_minutes,\n",
    "                            epoch_seconds,\n",
    "                            clock_biases, \n",
    "                            ver_names, \n",
    "                            file_names))\n",
    "        \n",
    "        combined_sorted = sorted(combined, key=lambda x: (x[1], x[2], x[3], x[4], x[5], x[6]))\n",
    "\n",
    "        sv_names_com,epoch_years_com,epoch_months_com,epoch_days_com,epoch_hours_com,epoch_minutes_com,epoch_seconds_com,clock_biases_com, ver_names_com, file_names_com = zip(*combined_sorted)\n",
    "\n",
    "        sv_names_com = list(sv_names_com)\n",
    "        epoch_years_com = list(epoch_years_com)\n",
    "        epoch_months_com = list(epoch_months_com)\n",
    "        epoch_days_com = list(epoch_days_com)\n",
    "        epoch_hours_com = list(epoch_hours_com)\n",
    "        epoch_minutes_com = list(epoch_minutes_com)\n",
    "        epoch_seconds_com = list(epoch_seconds_com)\n",
    "        clock_biases_com = list(clock_biases_com)\n",
    "        ver_names_com = list(ver_names_com)\n",
    "        file_names_com = list(file_names_com)\n",
    "\n",
    "        print(f\"Data is sorted by ascending epoch for GPS week {week} has been completed.\")\n",
    "\n",
    "        npz_filename = f'gps_{week}.npz'\n",
    "\n",
    "        np.savez(npz_filename, \n",
    "                 satellite=sv_names_com, \n",
    "                 yyyy=epoch_years_com, \n",
    "                 mm=epoch_months_com, \n",
    "                 dd=epoch_days_com, \n",
    "                 hh=epoch_hours_com, \n",
    "                 mi=epoch_minutes_com, \n",
    "                 ss=epoch_seconds_com, \n",
    "                 clock_bias=clock_biases_com, \n",
    "                 ver = ver_names_com, \n",
    "                 files = file_names_com)\n",
    "\n",
    "        print(f\"npz file for GPS week {week} has been created and stored as {npz_filename}.\")\n",
    "\n",
    "        print(f\"Data final product collection for GPS week {week} has been completed.\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for week {week}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36a9cac5-6284-4ae5-9b4c-71053adc56d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading file 1 out of 25\n",
      "Done reading file 2 out of 25\n",
      "Done reading file 3 out of 25\n",
      "Done reading file 4 out of 25\n",
      "Done reading file 5 out of 25\n",
      "Done reading file 6 out of 25\n",
      "Done reading file 7 out of 25\n",
      "Done reading file 8 out of 25\n",
      "Done reading file 9 out of 25\n",
      "Done reading file 10 out of 25\n",
      "Done reading file 11 out of 25\n",
      "Done reading file 12 out of 25\n",
      "Done reading file 13 out of 25\n",
      "Done reading file 14 out of 25\n",
      "Done reading file 15 out of 25\n",
      "Done reading file 16 out of 25\n",
      "Done reading file 17 out of 25\n",
      "Done reading file 18 out of 25\n",
      "Done reading file 19 out of 25\n",
      "Done reading file 20 out of 25\n",
      "Done reading file 21 out of 25\n",
      "Done reading file 22 out of 25\n",
      "Done reading file 23 out of 25\n",
      "Done reading file 24 out of 25\n",
      "Done reading file 25 out of 25\n",
      "SV Names for GPS week 2035 have been saved.\n",
      "Epoch Years for GPS week 2035 have been saved.\n",
      "Epoch Months for GPS week 2035 have been saved.\n",
      "Epoch Days for GPS week 2035 have been saved.\n",
      "Epoch Hours for GPS week 2035 have been saved.\n",
      "Epoch Minutes for GPS week 2035 have been saved.\n",
      "Epoch Seconds for GPS week 2035 have been saved.\n",
      "Clock biases (seconds) for GPS week 2035 have been saved.\n",
      "Versions for GPS week 2035 have been saved.\n",
      "Filepaths for GPS week 2035 have been saved.\n",
      "Data is sorted by ascending epoch for GPS week 2035 has been completed.\n",
      "npz file for GPS week 2035 has been created and stored as gps_2035.npz.\n",
      "Data final product collection for GPS week 2035 has been completed.\n",
      "CPU times: user 6.89 s, sys: 492 ms, total: 7.38 s\n",
      "Wall time: 7.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fetch_clk(2035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd714739-da69-4b49-8751-06770aa6313d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
