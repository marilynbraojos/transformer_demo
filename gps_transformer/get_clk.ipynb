{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c9c05d-936a-4baa-949e-72deea387a40",
   "metadata": {},
   "source": [
    "**This program is complete**\n",
    "\n",
    "**Author:** Marilyn Braojos \n",
    "\n",
    "**Purpose:** This program aims to connect to the CDDIS servers to obtain GPS final clock products. It is separated into 3 main parts: \n",
    "\n",
    "* Connecting to CDDIS servers\n",
    "* Downloading data for a given GPS week\n",
    "* Saving data for that week as an npz file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a2dc2-8e8c-4d08-a044-0b765bf0c73e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d95cfd-a3cf-46ac-bcb2-8adc8f853663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP_TLS\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec18f9-beaf-4e87-9647-663f6d63ba77",
   "metadata": {},
   "source": [
    "# FTP Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dca82e7-9488-43e7-a145-a07bbd90be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"gdc.cddis.eosdis.nasa.gov\"\n",
    "port = 21  # passive mode\n",
    "username = \"anonymous\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6df77bb-4454-4d92-b36e-87f0079fdda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx    1 ftp      ftp             8 Sep 06  2022 GSAC -> pub/GSAC\n",
      "lrwxrwxrwx    1 ftp      ftp             9 Sep 06  2022 doris -> pub/doris\n",
      "lrwxrwxrwx    1 ftp      ftp            11 Sep 06  2022 glonass -> pub/glonass\n",
      "lrwxrwxrwx    1 ftp      ftp             7 Sep 06  2022 gnss -> pub/gps\n",
      "lrwxrwxrwx    1 ftp      ftp             7 Sep 06  2022 gps -> pub/gps\n",
      "drwxrwxr-x   26 ftp      ftp          4096 Jan 01 00:16 highrate\n",
      "lrwxrwxrwx    1 ftp      ftp             8 Sep 06  2022 misc -> pub/misc\n",
      "lrwxrwxrwx    1 ftp      ftp            12 Sep 06  2022 products -> pub/products\n",
      "drwxrwxr-x   13 ftp      ftp          4096 Feb 21  2023 pub\n",
      "lrwxrwxrwx    1 ftp      ftp            11 Sep 06  2022 reports -> pub/reports\n",
      "lrwxrwxrwx    1 ftp      ftp             7 Sep 06  2022 slr -> pub/slr\n",
      "lrwxrwxrwx    1 ftp      ftp             8 Sep 06  2022 vlbi -> pub/vlbi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'226 Directory send OK.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp = FTP_TLS()\n",
    "ftp.connect(host, port)\n",
    "ftp.login(username, password)\n",
    "ftp.prot_p()\n",
    "ftp.retrlines('LIST') # list files in server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b7957-7692-4f28-8421-15c03df8fcc9",
   "metadata": {},
   "source": [
    "# Download and Save Data Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04163bde-35fb-4deb-b9a1-f8570b29e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(week):\n",
    "        try:\n",
    "            base_dir = '/pub/gps/products'\n",
    "            ftp.cwd(base_dir)\n",
    "            \n",
    "            week_folder = f\"{week}\"\n",
    "            ftp.cwd(week_folder)\n",
    "        \n",
    "            # List all files in the directory\n",
    "            \n",
    "            files = []\n",
    "            ftp.retrlines('NLST', files.append)\n",
    "    \n",
    "            clk_files = [file for file in files if file.endswith('.CLK.gz')] # CLK is case-sensitive\n",
    "    \n",
    "            data_dir = 'clk'\n",
    "            new_folder = os.path.join(data_dir, f'gps_{week}')\n",
    "            os.makedirs(new_folder, exist_ok=True)\n",
    "    \n",
    "            for i, clk_file in enumerate(clk_files):\n",
    "                local_filename = os.path.join(new_folder, clk_file)\n",
    "                \n",
    "                with open(local_filename, 'wb') as f:\n",
    "                      ftp.retrbinary(f\"RETR {clk_file}\", f.write)\n",
    "    \n",
    "                if clk_file.endswith('.gz'):\n",
    "                    local_uncompressed = local_filename[:-3]\n",
    "                    with gzip.open(local_filename, 'rb') as gzipped_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                         decompressed_file.write(gzipped_file.read())\n",
    "                    files.append(local_uncompressed)\n",
    "\n",
    "                print(f\"Done saving file {i + 1} out of {len(clk_files)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for week {week}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4744770-0f64-44ba-a2a6-a066464a5905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving file 1 out of 25\n",
      "Done saving file 2 out of 25\n",
      "Done saving file 3 out of 25\n",
      "Done saving file 4 out of 25\n",
      "Done saving file 5 out of 25\n",
      "Done saving file 6 out of 25\n",
      "Done saving file 7 out of 25\n",
      "Done saving file 8 out of 25\n",
      "Done saving file 9 out of 25\n",
      "Done saving file 10 out of 25\n",
      "Done saving file 11 out of 25\n",
      "Done saving file 12 out of 25\n",
      "Done saving file 13 out of 25\n",
      "Done saving file 14 out of 25\n",
      "Done saving file 15 out of 25\n",
      "Done saving file 16 out of 25\n",
      "Done saving file 17 out of 25\n",
      "Done saving file 18 out of 25\n",
      "Done saving file 19 out of 25\n",
      "Done saving file 20 out of 25\n",
      "Done saving file 21 out of 25\n",
      "Done saving file 22 out of 25\n",
      "Done saving file 23 out of 25\n",
      "Done saving file 24 out of 25\n",
      "Done saving file 25 out of 25\n",
      "CPU times: user 2.68 s, sys: 1.19 s, total: 3.87 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "fetch_data(2035)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8407e-ad3e-4a03-9db4-cad6dacb20f9",
   "metadata": {},
   "source": [
    "# Save Relevant IGS Data Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d6c63-620d-4cc7-beda-a536eabf5772",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebdff2d7-58c2-4d22-924f-7c0bf920552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_clks(week):\n",
    "    try:\n",
    "        base_dir = 'clk'        \n",
    "        week_folder = f\"gps_{week}\"\n",
    "        target_dir = os.path.join(base_dir, week_folder)\n",
    "\n",
    "        if not os.path.isdir(target_dir):\n",
    "            raise FileNotFoundError(f\"Directory {target_dir} does not exist.\")\n",
    "\n",
    "\n",
    "        clk_files = [file for file in os.listdir(target_dir) if file.endswith('.CLK')] # CLK is case-sensitive\n",
    "        \n",
    "        data = []\n",
    "        line_ct = 0\n",
    "\n",
    "\n",
    "        for i, clk_file in enumerate(clk_files):\n",
    "            file_path = os.path.join(target_dir, clk_file) \n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                first_line = file.readline()\n",
    "                is_version_3 = False\n",
    "                is_not_version_3 = False\n",
    "                end_header = False\n",
    "\n",
    "                if '3.04' in first_line[0:21]: \n",
    "                    is_version_3 = True\n",
    "                else:\n",
    "                    is_not_version_3 = True\n",
    "                \n",
    "                for line in file:\n",
    "                                        \n",
    "                    if not end_header:\n",
    "                        if 'END OF HEADER' in line:\n",
    "                            end_header = True\n",
    "                        continue\n",
    "                    \n",
    "                    if line.startswith('AS'):\n",
    "                        if end_header: \n",
    "                            if is_version_3:   \n",
    "                                if line[3:13].startswith('G'):\n",
    "                                    clock_data_type = line[0:3]\n",
    "                                    sv_name = line[3:13]\n",
    "                                    epoch_year = int(line[13:18])\n",
    "                                    epoch_month = int(line[18:21])\n",
    "                                    epoch_day = int(line[21:24])\n",
    "                                    epoch_hour = int(line[24:27])\n",
    "                                    epoch_minute = int(line[27:30])\n",
    "                                    epoch_second = float(line[30:40])\n",
    "                                    num_data_value = int(line[40:45])\n",
    "                                    clock_bias = float(line[45:66].lower().replace('d', 'e'))\n",
    "                                    file_ver = \"Version 3.04\" \n",
    "                                    used_file = file_path\n",
    "                                            # clock_bias_stddev = float(columns[10].lower().replace('d', 'e')) if len(columns) > 10 else np.nan\n",
    "                                            # clock_rate = float(columns[11].lower().replace('d', 'e')) if len(columns) > 11 else np.nan\n",
    "                                            # clock_rate_stddev = float(columns[12].lower().replace('d', 'e')) if len(columns) > 12 else np.nan\n",
    "                                            # clock_acceleration = float(columns[13].lower().replace('d', 'e')) if len(columns) > 13 else np.nan\n",
    "                                            # clock_acceleration_stddev = float(columns[14].lower().replace('d', 'e')) if len(columns) > 14 else np.nan\n",
    "                                            \n",
    "                                    row = {\n",
    "                                        'Clock Data Type': clock_data_type,\n",
    "                                        'SV Name': sv_name,\n",
    "                                        'Epoch Year': epoch_year,\n",
    "                                        'Epoch Month': epoch_month,\n",
    "                                        'Epoch Day': epoch_day,\n",
    "                                        'Epoch Hour': epoch_hour,\n",
    "                                        'Epoch Minute': epoch_minute,\n",
    "                                        'Epoch Second': epoch_second,\n",
    "                                        'Number of Data Values to Follow': num_data_value,\n",
    "                                        'Clock Bias (seconds)': clock_bias,\n",
    "                                        'Version': file_ver,\n",
    "                                        'File': file_path,\n",
    "                                                    # 'Clock Bias StdDev (seconds)': clock_bias_stddev,\n",
    "                                                    # 'Clock Rate (dimensionless)': clock_rate,\n",
    "                                                    # 'Clock Rate StdDev (dimensionless)': clock_rate_stddev,\n",
    "                                                    # 'Clock Acceleration (per second)': clock_acceleration,\n",
    "                                                    # 'Clock Acceleration StdDev (per second)': clock_acceleration_stddev,\n",
    "                                                    }\n",
    "                                    data.append(row)\n",
    "    \n",
    "                            # https://files.igs.org/pub/data/format/rinex_clock300.txt\n",
    "                            elif is_not_version_3:   \n",
    "                                if line[3:8].startswith('G'):\n",
    "                                    clock_data_type = line[0:3]\n",
    "                                    sv_name = line[3:8]\n",
    "                                    epoch_year = int(line[8:12])\n",
    "                                    epoch_month = int(line[12:15])\n",
    "                                    epoch_day = int(line[15:18])\n",
    "                                    epoch_hour = int(line[18:21])\n",
    "                                    epoch_minute = int(line[21:24])\n",
    "                                    epoch_second = float(line[24:34])\n",
    "                                    num_data_value = int(line[34:40])\n",
    "                                    clock_bias = float(line[40:59].lower().replace('d', 'e'))\n",
    "                                    file_ver = \"NOT version 3.04\" \n",
    "                                    used_file = file_path\n",
    "                                            # clock_bias_stddev = float(columns[10].lower().replace('d', 'e')) if len(columns) > 10 else np.nan\n",
    "                                            # clock_rate = float(columns[11].lower().replace('d', 'e')) if len(columns) > 11 else np.nan\n",
    "                                            # clock_rate_stddev = float(columns[12].lower().replace('d', 'e')) if len(columns) > 12 else np.nan\n",
    "                                            # clock_acceleration = float(columns[13].lower().replace('d', 'e')) if len(columns) > 13 else np.nan\n",
    "                                            # clock_acceleration_stddev = float(columns[14].lower().replace('d', 'e')) if len(columns) > 14 else np.nan\n",
    "                                            \n",
    "                                    row = {\n",
    "                                        'Clock Data Type': clock_data_type,\n",
    "                                        'SV Name': sv_name,\n",
    "                                        'Epoch Year': epoch_year,\n",
    "                                        'Epoch Month': epoch_month,\n",
    "                                        'Epoch Day': epoch_day,\n",
    "                                        'Epoch Hour': epoch_hour,\n",
    "                                        'Epoch Minute': epoch_minute,\n",
    "                                        'Epoch Second': epoch_second,\n",
    "                                        'Number of Data Values to Follow': num_data_value,\n",
    "                                        'Clock Bias (seconds)': clock_bias,\n",
    "                                        'Version': file_ver,\n",
    "                                        'File': file_path,\n",
    "                                                    # 'Clock Bias StdDev (seconds)': clock_bias_stddev,\n",
    "                                                    # 'Clock Rate (dimensionless)': clock_rate,\n",
    "                                                    # 'Clock Rate StdDev (dimensionless)': clock_rate_stddev,\n",
    "                                                    # 'Clock Acceleration (per second)': clock_acceleration,\n",
    "                                                    # 'Clock Acceleration StdDev (per second)': clock_acceleration_stddev,\n",
    "                                                    }\n",
    "                                    data.append(row)\n",
    "\n",
    "            print(f\"Done reading file {i + 1} out of {len(clk_files)}\")\n",
    "        \n",
    "        sv_names = [entry['SV Name'] for entry in data]\n",
    "        print(f\"SV Names for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_years = [entry['Epoch Year'] for entry in data]\n",
    "        print(f\"Epoch Years for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_months = [entry['Epoch Month'] for entry in data]\n",
    "        print(f\"Epoch Months for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_days = [entry['Epoch Day'] for entry in data]\n",
    "        print(f\"Epoch Days for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_hours = [entry['Epoch Hour'] for entry in data]\n",
    "        print(f\"Epoch Hours for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_minutes = [entry['Epoch Minute'] for entry in data]\n",
    "        print(f\"Epoch Minutes for GPS week {week} have been saved.\")\n",
    "        \n",
    "        epoch_seconds = [entry['Epoch Second'] for entry in data]\n",
    "        print(f\"Epoch Seconds for GPS week {week} have been saved.\")\n",
    "        \n",
    "        clock_biases = [entry['Clock Bias (seconds)'] for entry in data]\n",
    "        print(f\"Clock biases (seconds) for GPS week {week} have been saved.\")\n",
    "\n",
    "        ver_names = [entry['Version'] for entry in data]\n",
    "        print(f\"Versions for GPS week {week} have been saved.\")\n",
    "\n",
    "        file_names = [entry['File'] for entry in data]\n",
    "        print(f\"Filepaths for GPS week {week} have been saved.\")\n",
    "\n",
    "        combined = list(zip(sv_names,epoch_years,epoch_months,epoch_days,epoch_hours,epoch_minutes,epoch_seconds,clock_biases, ver_names, file_names))\n",
    "        combined_sorted = sorted(combined, key=lambda x: (x[1], x[2], x[3], x[4], x[5], x[6]))\n",
    "\n",
    "        sv_names_com,epoch_years_com,epoch_months_com,epoch_days_com,epoch_hours_com,epoch_minutes_com,epoch_seconds_com,clock_biases_com, ver_names_com, file_names_com = zip(*combined_sorted)\n",
    "\n",
    "        sv_names_com = list(sv_names_com)\n",
    "        epoch_years_com = list(epoch_years_com)\n",
    "        epoch_months_com = list(epoch_months_com)\n",
    "        epoch_days_com = list(epoch_days_com)\n",
    "        epoch_hours_com = list(epoch_hours_com)\n",
    "        epoch_minutes_com = list(epoch_minutes_com)\n",
    "        epoch_seconds_com = list(epoch_seconds_com)\n",
    "        clock_biases_com = list(clock_biases_com)\n",
    "        ver_names_com = list(ver_names_com)\n",
    "        file_names_com = list(file_names_com)\n",
    "\n",
    "        print(f\"Data is sorted by ascending epoch for GPS week {week} has been completed.\")\n",
    "\n",
    "        np.savez(f'gps_{week}.npz', satellite=sv_names_com, yyyy=epoch_years_com, mm=epoch_months_com, dd=epoch_days_com, hh=epoch_hours_com, mi=epoch_minutes_com, ss=epoch_seconds_com, clock_bias=clock_biases_com, ver = ver_names_com, files = file_names_com)\n",
    "        print(f\"npz file for GPS week {week} has been created.\")\n",
    "\n",
    "        print(f\"Data collection for GPS week {week} has been completed.\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for week {week}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a9cac5-6284-4ae5-9b4c-71053adc56d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading file 1 out of 25\n",
      "Done reading file 2 out of 25\n",
      "Done reading file 3 out of 25\n",
      "Done reading file 4 out of 25\n",
      "Done reading file 5 out of 25\n",
      "Done reading file 6 out of 25\n",
      "Done reading file 7 out of 25\n",
      "Done reading file 8 out of 25\n",
      "Done reading file 9 out of 25\n",
      "Done reading file 10 out of 25\n",
      "Done reading file 11 out of 25\n",
      "Done reading file 12 out of 25\n",
      "Done reading file 13 out of 25\n",
      "Done reading file 14 out of 25\n",
      "Done reading file 15 out of 25\n",
      "Done reading file 16 out of 25\n",
      "Done reading file 17 out of 25\n",
      "Done reading file 18 out of 25\n",
      "Done reading file 19 out of 25\n",
      "Done reading file 20 out of 25\n",
      "Done reading file 21 out of 25\n",
      "Done reading file 22 out of 25\n",
      "Done reading file 23 out of 25\n",
      "Done reading file 24 out of 25\n",
      "Done reading file 25 out of 25\n",
      "SV Names for GPS week 2035 have been saved.\n",
      "Epoch Years for GPS week 2035 have been saved.\n",
      "Epoch Months for GPS week 2035 have been saved.\n",
      "Epoch Days for GPS week 2035 have been saved.\n",
      "Epoch Hours for GPS week 2035 have been saved.\n",
      "Epoch Minutes for GPS week 2035 have been saved.\n",
      "Epoch Seconds for GPS week 2035 have been saved.\n",
      "Clock biases (seconds) for GPS week 2035 have been saved.\n",
      "Versions for GPS week 2035 have been saved.\n",
      "Filepaths for GPS week 2035 have been saved.\n",
      "Data is sorted by ascending epoch for GPS week 2035 has been completed.\n",
      "npz file for GPS week 2035 has been created.\n",
      "Data collection for GPS week 2035 has been completed.\n",
      "CPU times: user 7.68 s, sys: 686 ms, total: 8.37 s\n",
      "Wall time: 8.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fetch_clks(2035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd714739-da69-4b49-8751-06770aa6313d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
