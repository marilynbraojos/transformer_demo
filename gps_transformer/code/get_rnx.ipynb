{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd842d12-8727-4dcb-98bc-9a922db21eba",
   "metadata": {},
   "source": [
    "# get_rnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d33b4b-0295-4b0e-a2be-c8ae5b3d1157",
   "metadata": {},
   "source": [
    "**Author:** Marilyn Braojos Gutierrez\\\n",
    "**Purpose:** This program aims to download and uncompress RINEX format files with GPS satellite broadcast information. The program only obtains daily files.\\\n",
    "**PhD Milestone:** #1: *Leverage deep learning models to GPS satellite clock bias corrections.*\\\n",
    "**Project:** This program is Step (1) in this PhD milestone. Obtaining the data is the first critical step.\\\n",
    "**References:**\\\n",
    "[1] https://cddis.nasa.gov/Data_and_Derived_Products/GNSS/broadcast_ephemeris_data.html#GPShourly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592786da-3010-4e4a-b267-f1a1bea9e887",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d95cfd-a3cf-46ac-bcb2-8adc8f853663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP_TLS                                    # https://docs.python.org/3/library/ftplib.html\n",
    "import gzip                                                   # https://docs.python.org/3/library/gzip.html\n",
    "import matplotlib.pyplot as plt                               # https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html\n",
    "import numpy as np                                            # https://numpy.org/\n",
    "import os                                                     # https://docs.python.org/3/library/os.html\n",
    "import time                                                   # https://docs.python.org/3/library/time.html\n",
    "from unlzw import unlzw                                       # https://python-unlzw.readthedocs.io/_/downloads/en/latest/pdf/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec18f9-beaf-4e87-9647-663f6d63ba77",
   "metadata": {},
   "source": [
    "# Connecting to NASA's CDDIS FTP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0a667-c54e-4ecc-b76d-99b0d3e56269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cddis.nasa.gov/Data_and_Derived_Products/GNSS/GNSS_data_and_product_archive.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca82e7-9488-43e7-a145-a07bbd90be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"gdc.cddis.eosdis.nasa.gov\"                                    # FTP server host\n",
    "port = 21                                                             # set port (21 is std port for FTP in passive mode)\n",
    "username = \"anonymous\"\n",
    "password = \"\"\n",
    "timeout = 30                                                          # connection timeout (seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df77bb-4454-4d92-b36e-87f0079fdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp = FTP_TLS(timeout=timeout)\n",
    "ftp.connect(host, port)\n",
    "ftp.login(username, password)\n",
    "ftp.prot_p()\n",
    "ftp.retrlines('LIST')                                                 # list files in server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb919a-d53d-456a-8db2-0d7d60a2263d",
   "metadata": {},
   "source": [
    "# Fetching and Uncompressing Daily GPS Data from FTP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3153dce-d43d-4848-a1ab-5c42b6cde7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(yr):\n",
    "\n",
    "    '''\n",
    "    Download and uncompress daily GPS broadcast RINEX files.\n",
    "\n",
    "    Parameters:\n",
    "    yr (string): year of interest YYYY.\n",
    "    \n",
    "    Returns:\n",
    "    N/A.\n",
    "\n",
    "    Raises: \n",
    "    Error: If connection is to server is lost. \n",
    "    '''\n",
    "    \n",
    "    retries = 3 \n",
    "    base_dir = f'/pub/gps/data/daily/{yr}'\n",
    "    data_dir = 'rnx'\n",
    "\n",
    "    for dd in range(1,366):\n",
    "        start_time = time.time()\n",
    "        dd_str = f'{dd:03d}'\n",
    "        new_dir = os.path.join(data_dir, f'gps_rnx_daily_{yr}{dd_str}')\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "        for _ in range(retries): \n",
    "            try:    \n",
    "                ftp.cwd(base_dir)\n",
    "                dd_dir = os.path.join(base_dir, dd_str)\n",
    "                ftp.cwd(dd_dir)\n",
    "    \n",
    "                yr_suff = yr[-2:]\n",
    "                year_suffix = f'{yr_suff}n'\n",
    "                ftp.cwd(year_suffix)\n",
    "                files = []\n",
    "                                \n",
    "                ftp.retrlines('NLST', files.append)\n",
    "                            \n",
    "                # rnx_files = [file for file in files if file.endswith('GN.rnx.gz') or file.endswith('n.Z')] # case-sensitive\n",
    "                rnx_files = [file for file in files if file.endswith('GN.rnx.gz')] # case-sensitive\n",
    "                                            \n",
    "                for i, rnx_file in enumerate(rnx_files):\n",
    "                    local_filename = os.path.join(new_dir, rnx_file)\n",
    "                                                \n",
    "                    with open(local_filename, 'wb') as f:\n",
    "                        ftp.retrbinary(f\"RETR {rnx_file}\", f.write)\n",
    "                                            \n",
    "                    if rnx_file.endswith('.gz'):\n",
    "                        local_uncompressed = local_filename[:-3]\n",
    "                        try: \n",
    "                            with gzip.open(local_filename, 'rb') as gzipped_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                                decompressed_file.write(gzipped_file.read())\n",
    "                                files.append(local_uncompressed)\n",
    "                        except Exception as e: \n",
    "                            print(f\"Error uncompressing file {local_filename}: {e}. Will begin uncompressing file as a UNIX compressed file\")\n",
    "                            with open(local_filename, 'rb') as compressed_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                                decompressed_file.write(unlzw(compressed_file.read()))\n",
    "                                files.append(local_uncompressed)\n",
    "                                print(f\"Successfully uncompressed and saved file {local_filename} as a UNIX compressed file\")\n",
    "                                    \n",
    "                        print(f\"Done saving file {i + 1} out of {len(rnx_files)} for Day/Year: {dd}/{yr}\")\n",
    "    \n",
    "                #         # elif rnx_file.endswith('.Z'):\n",
    "                #         #     local_uncompressed = local_filename[:-2]\n",
    "                #         #     try: \n",
    "                #         #         with open(local_filename, 'rb') as compressed_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "                #         #             decompressed_file.write(unlzw(compressed_file.read()))\n",
    "                #         #             files.append(local_uncompressed)\n",
    "                #         #     except Exception as e: \n",
    "                #         #         print(f\"Error uncompressing a UNIX compressed file {local_filename}: {e}\")\n",
    "    \n",
    "                #             # print(f\"Done saving file {i + 1} out of {len(rnx_files)} for Day/Year: {dd}/{yr}\")\n",
    "                    \n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                print(f\"Done uncompressing and saving files for Day/Year: {dd}/{yr} in folder: {new_dir}. The elapsed time of this operation was {elapsed_time:.2f} seconds\")      \n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {_ + 1} for Day/Year: {dd}/{yr}: {e}\")\n",
    "                if _ == retries - 1:\n",
    "                    print(f\"Failed to fetch data for Day/Year: {dd}/{yr} after {retries} attempts.\")\n",
    "                time.sleep(5)\n",
    "\n",
    "    print(f\"Done uncompressing and saving all files for Year: {yr} in folder: {new_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1407d-c016-42ef-8062-cbf1ec13c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yrs = range(2018,2019)\n",
    "\n",
    "for yr in yrs: \n",
    "    fetch_data(f'{yr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b7957-7692-4f28-8421-15c03df8fcc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04163bde-35fb-4deb-b9a1-f8570b29e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_data(yr):\n",
    "#         try:\n",
    "#             base_dir = f'/pub/gps/data/hourly/{yr}'\n",
    "#             ftp.cwd(base_dir)\n",
    "            \n",
    "#             data_dir = 'rnx'\n",
    "#             # new_dir = os.path.join(data_dir, f'gps_rnx_{yr}{dd}')\n",
    "#             # os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "#             for dd in range(1,365):\n",
    "\n",
    "#                 dd_str = f'{dd:03d}'\n",
    "#                 new_dir = os.path.join(data_dir, f'gps_rnx_{yr}{dd_str}')\n",
    "#                 os.makedirs(new_dir, exist_ok=True)\n",
    "#                 dd_dir = os.path.join(base_dir, dd_str)\n",
    "#                 ftp.cwd(dd_dir)\n",
    "\n",
    "#                 for hr in range(24):      \n",
    "#                     files = []\n",
    "#                     hr_str = f'{hr:02d}'\n",
    "#                     hour_dir = os.path.join(dd_dir, hr_str)\n",
    "#                     ftp.cwd(hour_dir)\n",
    "                            \n",
    "#                     ftp.retrlines('NLST', files.append)\n",
    "                        \n",
    "#                     rnx_files = [file for file in files if file.endswith('GN.rnx.gz')] # case-sensitive\n",
    "                                        \n",
    "#                     for i, rnx_file in enumerate(rnx_files):\n",
    "#                         local_filename = os.path.join(new_dir, rnx_file)\n",
    "                                            \n",
    "#                         with open(local_filename, 'wb') as f:\n",
    "#                             ftp.retrbinary(f\"RETR {rnx_file}\", f.write)\n",
    "                                        \n",
    "#                         if rnx_file.endswith('.gz'):\n",
    "#                             local_uncompressed = local_filename[:-3]\n",
    "#                             try: \n",
    "#                                 with gzip.open(local_filename, 'rb') as gzipped_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "#                                     decompressed_file.write(gzipped_file.read())\n",
    "#                                     files.append(local_uncompressed)\n",
    "#                             except Exception as e: \n",
    "#                                 print(f\"Error uncompressing file {local_filename}: {e}. Will begin uncompressing file as a UNIX compressed file\")\n",
    "#                                 with open(local_filename, 'rb') as compressed_file, open(local_uncompressed, 'wb') as decompressed_file:\n",
    "#                                     decompressed_file.write(unlzw(compressed_file.read()))\n",
    "#                                     files.append(local_uncompressed)\n",
    "#                                     print(f\"Successfully uncompressed and saved file {local_filename} as a UNIX compressed file\")\n",
    "                            \n",
    "#                         print(f\"Done saving file {i + 1} out of {len(rnx_files)} for Hour: {hr} Day/Year: {dd}/{yr}\")\n",
    "#                 print(f\"Done uncompressing and saving files for Day/Year: {dd}/{yr} in folder: {new_dir}\")      \n",
    "#             print(f\"Done uncompressing and saving all files for Year: {yr} in folder: {new_dir}\")                \n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error fetching data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
