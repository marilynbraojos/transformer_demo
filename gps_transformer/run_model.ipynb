{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61b1b06-89e8-4cff-9656-e6dbf10bc6e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e603fcf4-44c0-4304-a376-c04a2b04409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decc72d7-aabf-4db9-b949-50639cdc9d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matching_epochs',\n",
       " 'matching_clock_bias',\n",
       " 'matching_poly_values',\n",
       " 'correction_vals']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('/Volumes/MARI/ssdl_gps/correction_data/correction_data_2019_str_update.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bc8914-e801-4fb6-9764-882fc088ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = data['matching_epochs']\n",
    "final_bias = data['matching_clock_bias']\n",
    "broadcast_bias = data['matching_poly_values']\n",
    "correction = data['correction_vals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611cb121-4ec4-4175-858f-9b322075c279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Removing Outliers (Considering Only Data b/w 1st and 99th Percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb2291-2000-47fa-973e-3bc4848d04bd",
   "metadata": {},
   "source": [
    "The method described replaces values outside the 5th and 95th percentiles with the 5th or 95th percentile values, respectively. The length of data does not change; it's modifying the values within the original dataset.\n",
    "\n",
    "Clipping: Any values below the 5th percentile are set to the 5th percentile value, and any values above the 95th percentile are set to the 95th percentile value. This means that extreme values are capped but no data is added or removed; the dataset size remains the same.\n",
    "\n",
    "[Text partially provided from ChatGPT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88073f58-3c43-4e4b-a492-e86d78c98a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_biases = np.column_stack((final_bias, broadcast_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5415361b-66c9-451e-a6c8-b5740cf0773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_stacked_bias_1st = np.percentile(stacked_biases, 1)\n",
    "percentiles_stacked_bias_99th = np.percentile(stacked_biases, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117b88c9-3c2e-4735-ab1f-0e1e35bdd614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.000275395740573028\n",
      "-6.418626571754036e-05\n"
     ]
    }
   ],
   "source": [
    "print(percentiles_stacked_bias_1st)\n",
    "print(percentiles_stacked_bias_99th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3340cd17-d940-4a7b-97df-fda95e2cf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_correction_1st = np.percentile(correction, 1)\n",
    "percentiles_correction_99th = np.percentile(correction, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1acf0400-bfe9-4ba3-a4fa-80445797e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3656707763352177e-09\n",
      "3.6908192275824645e-09\n"
     ]
    }
   ],
   "source": [
    "print(percentiles_correction_1st)\n",
    "print(percentiles_correction_99th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f072548-3c90-47ec-98e6-2aa75d8ff8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_stacked_bias = np.clip(stacked_biases, percentiles_stacked_bias_1st, percentiles_stacked_bias_99th)\n",
    "clipped_correction = np.clip(correction, percentiles_correction_1st, percentiles_correction_99th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffd90b6a-8dce-4d56-8f95-10be459abfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_final_bias = clipped_stacked_bias[:, 0]\n",
    "clipped_broadcast_bias = clipped_stacked_bias[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea7eeb3-ad17-47aa-b3f1-f4edadcb6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/Volumes/MARI/ssdl_gps/correction_data/correction_data_2019_outliers_1_99.npz',\n",
    "         matching_epochs=epochs,\n",
    "         matching_clock_bias=clipped_final_bias,\n",
    "         matching_poly_values=clipped_broadcast_bias,\n",
    "         correction_vals=clipped_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cab5c9f4-72ed-4378-9d68-b8b909dbd8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Clipped Final Bias: -6.418626571754036e-05\n",
      "Minimum Clipped Final Bias: -0.000275395740573028\n",
      "Maximum Clipped Broadcast Bias: -6.418626571754036e-05\n",
      "Minimum Clipped Broadcast Bias: -0.000275395740573028\n",
      "Maximum Clipped Correction: 3.6908192275824645e-09\n",
      "Minimum Clipped Correction: -1.3656707763352177e-09\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum Clipped Final Bias: {max(clipped_final_bias)}')\n",
    "print(f'Minimum Clipped Final Bias: {min(clipped_final_bias)}')\n",
    "print(f'Maximum Clipped Broadcast Bias: {max(clipped_broadcast_bias)}')\n",
    "print(f'Minimum Clipped Broadcast Bias: {min(clipped_broadcast_bias)}')\n",
    "print(f'Maximum Clipped Correction: {max(clipped_correction)}')\n",
    "print(f'Minimum Clipped Correction: {min(clipped_correction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8699657-74f2-4d72-91d6-ca57ae0a80ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Final Bias: -6.24509320829e-05\n",
      "Minimum Final Bias: -0.000278481206632\n",
      "Maximum Broadcast Bias: -6.24519193479468e-05\n",
      "Minimum Broadcast Bias: -0.0002776021137834\n",
      "Maximum Correction: 5.931226931664034e-09\n",
      "Minimum Correction: -4.122253926605666e-06\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum Final Bias: {max(final_bias)}')\n",
    "print(f'Minimum Final Bias: {min(final_bias)}')\n",
    "print(f'Maximum Broadcast Bias: {max(broadcast_bias)}')\n",
    "print(f'Minimum Broadcast Bias: {min(broadcast_bias)}')\n",
    "print(f'Maximum Correction: {max(correction)}')\n",
    "print(f'Minimum Correction: {min(correction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e88cc-7b83-4d4d-aa59-a46f15d14d66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plotting Data After Outlier Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5000a3e2-e10d-4d69-ae68-f4f65f35f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_datetimes = [datetime.strptime(ts, '%Y:%m:%d:%H:%M:%S') for ts in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db2e9cb4-f279-44a6-85f3-698cfec06a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 13):\n",
    "    start_date = datetime(2019, month, 1)\n",
    "    if month == 12:\n",
    "        end_date = datetime(2020, 1, 1)\n",
    "    else:\n",
    "        end_date = datetime(2019, month + 1, 1)\n",
    "\n",
    "    monthly_indices = [i for i, epoch in enumerate(time_datetimes) if start_date <= epoch < end_date]\n",
    "    monthly_epochs = [time_datetimes[i] for i in monthly_indices]\n",
    "    monthly_clock_bias = [clipped_final_bias[i] for i in monthly_indices]\n",
    "    monthly_poly_values = [clipped_broadcast_bias[i] for i in monthly_indices]\n",
    "    monthly_correction_vals = [clipped_correction[i] for i in monthly_indices]\n",
    "\n",
    "    # Plot clock_bias and poly_values\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.scatter(monthly_epochs, monthly_clock_bias, label='Clock Bias (Station: GRG)')\n",
    "    plt.scatter(monthly_epochs, monthly_poly_values, label='Broadcast Polynomial Values', s=5)\n",
    "    plt.xlabel('Time (YYYY:MM:DD:HH:MI:SS)')\n",
    "    plt.ylabel('Bias Values (s)')\n",
    "    # plt.ylim(-0.00002734, -0.00002722)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=5))  # Set major ticks every hour\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.25)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f'Clock Bias and Poly Values for G21 {start_date.strftime(\"%B %Y\")}')\n",
    "    plt.savefig(f'/Volumes/MARI/ssdl_gps/plots_outlier_1_99/clock_bias_poly_values_{month:02d}_2019.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot correction values\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.scatter(monthly_epochs, monthly_correction_vals, label='Clock Bias Correction (s)')\n",
    "    plt.xlabel('Time (YYYY:MM:DD:HH:MI:SS)')\n",
    "    plt.ylabel('Bias Correction Values (s)')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=5))  # Set major ticks every hour\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.25)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f'Clock Bias Correction Values for G21 {start_date.strftime(\"%B %Y\")}')\n",
    "    plt.savefig(f'/Volumes/MARI/ssdl_gps/plots_outlier_1_99/correction_values_{month:02d}_2019.png')\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23a05c-febe-4c89-914a-ec360feca10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920baab2-31ea-431a-bcaa-847c4e4b7eb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93b4d7c4-ecf5-458b-8a8f-4e3a9a3ffc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26830159-e772-45be-9222-a98716c9a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_biases = scaler.fit_transform(clipped_stacked_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc020807-7d04-4042-b499-35dfa6aff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_final_bias = scaled_biases[:, 0]\n",
    "scaled_broadcast_bias = scaled_biases[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "309ffa04-122e-4504-8806-602e5e2f60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a6ca727-287a-475c-9434-9764ec6153fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_correction = correction_scaler.fit_transform(clipped_correction.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f9344f9-ceae-4330-9ad4-8620af73a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/Volumes/MARI/ssdl_gps/correction_data/correction_data_2019_minmaxscale_postoutlier.npz',\n",
    "         matching_epochs=epochs,\n",
    "         matching_clock_bias=scaled_final_bias,\n",
    "         matching_poly_values=scaled_broadcast_bias,\n",
    "         correction_vals=scaled_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "420468ab-6e09-47ed-86ea-9aa43aaff872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Scaled Final Bias: 0.9999999999999999\n",
      "Minimum Scaled Final Bias: 0.0\n",
      "Maximum Scaled Broadcast Bias: 0.9999999999999999\n",
      "Minimum Scaled Broadcast Bias: 0.0\n",
      "Maximum Scaled Correction: 0.9999999999999998\n",
      "Minimum Scaled Correction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum Scaled Final Bias: {max(scaled_final_bias)}')\n",
    "print(f'Minimum Scaled Final Bias: {min(scaled_final_bias)}')\n",
    "print(f'Maximum Scaled Broadcast Bias: {max(scaled_broadcast_bias)}')\n",
    "print(f'Minimum Scaled Broadcast Bias: {min(scaled_broadcast_bias)}')\n",
    "print(f'Maximum Scaled Correction: {max(scaled_correction)}')\n",
    "print(f'Minimum Scaled Correction: {min(scaled_correction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f4aae58-acdf-4d42-90d9-0c6fb7e6cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1, 13):\n",
    "    start_date = datetime(2019, month, 1)\n",
    "    if month == 12:\n",
    "        end_date = datetime(2020, 1, 1)\n",
    "    else:\n",
    "        end_date = datetime(2019, month + 1, 1)\n",
    "\n",
    "    monthly_indices = [i for i, epoch in enumerate(time_datetimes) if start_date <= epoch < end_date]\n",
    "    monthly_epochs = [time_datetimes[i] for i in monthly_indices]\n",
    "    monthly_clock_bias = [scaled_final_bias[i] for i in monthly_indices]\n",
    "    monthly_poly_values = [scaled_broadcast_bias[i] for i in monthly_indices]\n",
    "    monthly_correction_vals = [scaled_correction[i] for i in monthly_indices]\n",
    "\n",
    "    # Plot clock_bias and poly_values\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.scatter(monthly_epochs, monthly_clock_bias, label='Clock Bias (Station: GRG)')\n",
    "    plt.scatter(monthly_epochs, monthly_poly_values, label='Broadcast Polynomial Values', s=5)\n",
    "    plt.xlabel('Time (YYYY:MM:DD:HH:MI:SS)')\n",
    "    plt.ylabel('Bias Values (s)')\n",
    "    # plt.ylim(-0.00002734, -0.00002722)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=5))  # Set major ticks every hour\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.25)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f'Clock Bias and Poly Values for G21 {start_date.strftime(\"%B %Y\")}')\n",
    "    plt.savefig(f'/Volumes/MARI/ssdl_gps/plots_minmaxscaler/clock_bias_poly_values_{month:02d}_2019.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot correction values\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.scatter(monthly_epochs, monthly_correction_vals, label='Clock Bias Correction (s)')\n",
    "    plt.xlabel('Time (YYYY:MM:DD:HH:MI:SS)')\n",
    "    plt.ylabel('Bias Correction Values (s)')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=5))  # Set major ticks every hour\n",
    "    # plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.25)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.title(f'Clock Bias Correction Values for G21 {start_date.strftime(\"%B %Y\")}')\n",
    "    plt.savefig(f'/Volumes/MARI/ssdl_gps/plots_minmaxscaler/correction_values_{month:02d}_2019.png')\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c1ca1-1ff8-40f6-a39d-4b2632d19b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f9134a-a31c-4e84-9652-3efdac1a2267",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d6eb4-65f5-418d-ac6b-7bc7fecf6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07190e-284b-4e6d-aab6-28f2c6e2b786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4835960-4eb7-4781-b1c9-64fb2eddb23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0a2c7-93ae-4878-b87c-d50ab5d8a938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63fb07-09a3-4ad5-973c-851971ce0aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc89841-7b5e-42f3-a347-0fa22bf11532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f88bd-a174-444c-9f3d-4a8ffd4c7c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05152036-8c97-485e-9923-639dfaffe0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb339961-cd0a-47b2-975f-d0c70b8a621f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c80ba-09ff-4cec-8b58-433b8242665d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6fee6-7cd6-4734-8fcf-9089ea98d63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc5c2d-890d-45b6-bd94-319cc1224697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# # Load data\n",
    "# data = np.load('/Volumes/MARI/ssdl_gps/correction_data_2019_mo1.npz')\n",
    "\n",
    "# matching_poly_values = data['matching_poly_values']\n",
    "# correction_vals = data['correction_vals']\n",
    "\n",
    "# # Ensure data is in the correct shape [num_samples, num_features]\n",
    "# # Assuming each sample has one feature (i.e., 1D data)\n",
    "# matching_poly_values = matching_poly_values[:, np.newaxis]  # Shape: [num_samples, 1]\n",
    "# correction_vals = correction_vals[:, np.newaxis]  # Shape: [num_samples, 1]\n",
    "\n",
    "# # Apply min-max scaling\n",
    "# scaler_poly = MinMaxScaler()\n",
    "# scaler_correction = MinMaxScaler()\n",
    "\n",
    "# matching_poly_values_scaled = scaler_poly.fit_transform(matching_poly_values)\n",
    "# correction_vals_scaled = scaler_correction.fit_transform(correction_vals)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# train_size = int(0.7 * len(matching_poly_values_scaled))\n",
    "# test_size = len(matching_poly_values_scaled) - train_size\n",
    "\n",
    "# train_poly_values = matching_poly_values_scaled[:train_size]\n",
    "# train_correction_vals = correction_vals_scaled[:train_size]\n",
    "\n",
    "# test_poly_values = matching_poly_values_scaled[train_size:]\n",
    "# test_correction_vals = correction_vals_scaled[train_size:]\n",
    "\n",
    "# # Convert to torch tensors\n",
    "# train_poly_values = torch.from_numpy(train_poly_values).float()\n",
    "# train_correction_vals = torch.from_numpy(train_correction_vals).float()\n",
    "# test_poly_values = torch.from_numpy(test_poly_values).float()\n",
    "# test_correction_vals = torch.from_numpy(test_correction_vals).float()\n",
    "\n",
    "# # Create datasets\n",
    "# train_dataset = TensorDataset(train_poly_values, train_correction_vals)\n",
    "# test_dataset = TensorDataset(test_poly_values, test_correction_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce01cd8-77d8-410f-bac0-b87512fd0d9f",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952cb07-25e3-4c62-a8bb-dd286a826c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/Volumes/MARI/ssdl_gps/correction_data/correction_data_2019_mo1.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01675c5d-1b88-4a17-a665-dd0c7e0d8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test_correction_data_2019_mo1.npz',\n",
    "         correction_vals = data['correction_vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2945a06-510f-45d2-a7d9-d33d27bca3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea85fc-8f65-4f5f-838d-e786bdb6d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(data['correction_vals']))\n",
    "plt.scatter(x,data['correction_vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902abe8c-a23b-4ff7-9065-e755201a8122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adb5d129-3d5b-4dd4-b7d0-a9cfc3e566ec",
   "metadata": {},
   "source": [
    "# Transformer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83471a7-85e5-489a-98bf-e4e66a279982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(3)\n",
    "\n",
    "# def generate_data(data_path: Path, num_steps: int = 1000000, interval: float = 0.1) -> None:\n",
    "#     \"\"\"\n",
    "#     Generate synthetic data and save it to a specified file.\n",
    "\n",
    "#     Parameters ----------------------------------------------------------------\n",
    "#     data_path : Path\n",
    "#         The path where the generated data will be saved.\n",
    "#     num_steps : int, optional\n",
    "#         The number of data points to generate.\n",
    "#     interval : float, optional\n",
    "#         The spacing between data points in the x-axis (default is 0.1).\n",
    "\n",
    "#     Returns --------------------------------------------------------------------\n",
    "#     -------\n",
    "#     None\n",
    "#         The function saves the generated data to a file at `data_path`.\n",
    "#     \"\"\"\n",
    "#     x = np.linspace(0, num_steps * interval, num_steps)\n",
    "#     y = np.sin(x) + np.random.normal(0, 0.1, x.shape)\n",
    "\n",
    "#     np.savez(data_path, y=y)\n",
    "\n",
    "#     return num_steps, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e44a42-1a36-4c07-8b7d-9b0989ede134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sine = Path(\"sine_data.npz\")\n",
    "# sawtooth = Path(\"saw_data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0d653-18d4-4f1e-b553-ffb738c37512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# def generate_data(data_path: Path, num_steps: int = 1000000, interval: float = 0.1, waveform_type: str = 'sine') -> None:\n",
    "#     \"\"\"\n",
    "#     Generate synthetic data (sine or noisy sawtooth wave) and save it to a specified file.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data_path : Path\n",
    "#         The path where the generated data will be saved.\n",
    "#     num_steps : int, optional\n",
    "#         The number of data points to generate.\n",
    "#     interval : float, optional\n",
    "#         The spacing between data points in the x-axis (default is 0.1).\n",
    "#     waveform_type : str, optional\n",
    "#         Type of waveform to generate ('sine' or 'sawtooth'). Default is 'sine'.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     None\n",
    "#         The function saves the generated data to a file at `data_path`.\n",
    "#     \"\"\"\n",
    "#     if waveform_type == 'sine':\n",
    "#         x = np.linspace(0, num_steps * interval, num_steps)\n",
    "#         y = np.sin(x) + np.random.normal(0, 0.1, x.shape)\n",
    "#     elif waveform_type == 'sawtooth':\n",
    "#         sampling_rate = 4\n",
    "#         duration = 100000\n",
    "#         x = np.linspace(0.0, duration, int(duration * sampling_rate), endpoint=False)\n",
    "#         amplitude = 0.5  # Amplitude of the sawtooth wave\n",
    "#         noise_amplitude = 0.1  # Amplitude of the noise\n",
    "#         frequency = .04  # Frequency of the sawtooth wave in Hz\n",
    "\n",
    "#         # Sawtooth wave\n",
    "#         sawtooth_wave = amplitude * (2 * (frequency * x - np.floor(frequency * x + 0.5)))\n",
    "#         noise = noise_amplitude * np.random.randn(len(x))\n",
    "#         y = sawtooth_wave + noise\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported waveform_type. Choose 'sine' or 'sawtooth'.\")\n",
    "\n",
    "#     np.savez(data_path, y=y)\n",
    "\n",
    "#     return x, num_steps, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6823ab9-0c95-40c9-8ad2-908e648641ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_sine, num_steps, interval) = generate_data(sine, num_steps=1000000, interval=0.1, waveform_type='sine')\n",
    "# (x_saw, num_steps, interval) = generate_data(sawtooth, num_steps=1000000, interval=0.1, waveform_type='sawtooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5c8db-2ba9-4b86-9d6e-00de12f7f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x_sine, np.load('sine_data.npz')['y'], color='r', label='Noisy Sine Wave')\n",
    "# plt.grid(True)\n",
    "# plt.xlim(0,100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c7bbd-a544-4a44-9171-9b8916ba997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(x_saw, np.load('saw_data.npz')['y'], color='r', label='Noisy Sawtooth Wave')\n",
    "# plt.grid(True)\n",
    "# plt.xlim(0,100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531b5e1-4d46-4a6f-9394-b34ca99a6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(\n",
    "    sequence: np.ndarray, ratio: float = 0.8\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Splits a sequence into 2 (3) parts, as is required by our transformer\n",
    "    model.\n",
    "\n",
    "    Assume our sequence length is L, we then split this into src of length N\n",
    "    and tgt_y of length M, with N + M = L.\n",
    "    src, the first part of the input sequence, is the input to the encoder, and we\n",
    "    expect the decoder to predict tgt_y, the second part of the input sequence.\n",
    "    In addition we generate tgt, which is tgt_y but \"shifted left\" by one - i.e. it\n",
    "    starts with the last token of src, and ends with the second-last token in tgt_y.\n",
    "    This sequence will be the input to the decoder.\n",
    "\n",
    "\n",
    "    Args:\n",
    "\n",
    "        sequence: batched input sequences to split [bs, seq_len, num_features]\n",
    "        ratio: split ratio, N = ratio * L\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: src, tgt, tgt_y\n",
    "    \"\"\"\n",
    "    src_end = int(sequence.shape[1] * ratio)\n",
    "    # [bs, src_seq_len, num_features]\n",
    "    src = sequence[:, :src_end]\n",
    "    # [bs, tgt_seq_len, num_features]\n",
    "    tgt = sequence[:, src_end - 1 : -1]\n",
    "    # [bs, tgt_seq_len, num_features]\n",
    "    tgt_y = sequence[:, src_end:]\n",
    "\n",
    "    return src, tgt, tgt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe79fbd-3e4e-4a6d-b350-ccfbd1e13b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://pytorch.org/tutorials/beginner/transformer_tutorial.html,\n",
    "# only modified to account for \"batch first\"\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        d_model (int): Dimension of the model (embedding dimension)\n",
    "        dropout (float, optional): Dropout probability. Default is 0.1.\n",
    "        max_len (int, optional): Maximum length of input sequences. Default is 5000.\n",
    "\n",
    "      Attributes:\n",
    "        pe (torch.Tensor): Positional encoding tensor. Shape: (1, max_len, d_model)\n",
    "\n",
    "      Returns:\n",
    "        torch.Tensor: input tensor with added positional encoding.\n",
    "\n",
    "      \"\"\"\n",
    "      super().__init__()\n",
    "      self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "      position = torch.arange(max_len).unsqueeze(1)                           # 1-D tensor from 0 to max_len -1. Unsqueeze \"adds\" a superficial 1 dim.\n",
    "      div_term = torch.exp(\n",
    "          torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "      )\n",
    "      pe = torch.zeros(1, max_len, d_model)\n",
    "      pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "      pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "      self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "      \"\"\"Adds positional encoding to the given tensor.\n",
    "\n",
    "      Args:\n",
    "          x: tensor to add PE to [bs, seq_len, embed_dim]\n",
    "\n",
    "      Returns:\n",
    "          torch.Tensor: tensor with PE [bs, seq_len, embed_dim]\n",
    "      \"\"\"\n",
    "      x = x + self.pe[:, : x.size(1)]\n",
    "      return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067ee42-24dd-44c2-8c27-db191bcf95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerWithPE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, in_dim: int, out_dim: int, embed_dim: int, num_heads: int, num_layers: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a transformer model with positional encoding.\n",
    "\n",
    "        Args:\n",
    "            in_dim: number of input features\n",
    "            out_dim: number of features to predict\n",
    "            embed_dim: embed features to this dimension\n",
    "            num_heads: number of transformer heads\n",
    "            num_layers: number of encoder and decoder layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "\n",
    "        # transform input features into embedded features\n",
    "        self.encoder_embedding = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=embed_dim\n",
    "        )\n",
    "        self.decoder_embedding = torch.nn.Linear(\n",
    "            in_features=out_dim, out_features=embed_dim\n",
    "        )\n",
    "\n",
    "        # map output into output dimension\n",
    "        self.output_layer = torch.nn.Linear(in_features=embed_dim, out_features=out_dim)\n",
    "\n",
    "\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            d_model=embed_dim,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward function of the model.\n",
    "\n",
    "        Args:\n",
    "            src: input sequence to the encoder [bs, src_seq_len, num_features]\n",
    "            tgt: input sequence to the decoder [bs, tgt_seq_len, num_features]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: predicted sequence [bs, tgt_seq_len, feat_dim]\n",
    "        \"\"\"\n",
    "        # if self.train:\n",
    "        # Add noise to decoder inputs during training\n",
    "        # tgt = tgt + torch.normal(0, 0.1, size=tgt.shape).to(tgt.device)\n",
    "\n",
    "        # Embed encoder input and add positional encoding.\n",
    "        # [bs, src_seq_len, embed_dim]\n",
    "        src = self.encoder_embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "\n",
    "        # Generate mask to avoid attention to future outputs.\n",
    "        # [tgt_seq_len, tgt_seq_len]\n",
    "        tgt_mask = torch.nn.Transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "        # Embed decoder input and add positional encoding.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        tgt = self.decoder_embedding(tgt)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        # Get prediction from transformer and map to output dimension.\n",
    "        # [bs, tgt_seq_len, embed_dim]\n",
    "        pred = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        pred = self.output_layer(pred)\n",
    "\n",
    "        return pred                                                             # return predicted sequence\n",
    "\n",
    "\n",
    "    def infer(self, src: torch.Tensor, tgt_len: int) -> torch.Tensor:\n",
    "        \"\"\"Runs inference with the model, meaning: predicts future values\n",
    "        for an unknown sequence.\n",
    "        For this, iteratively generate the next output token while\n",
    "        feeding the already generated ones as input sequence to the decoder.\n",
    "\n",
    "        Args:\n",
    "            src: input to the encoder [bs, src_seq_len, num_features]\n",
    "            tgt_len: desired length of the output\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: inferred sequence\n",
    "        \"\"\"\n",
    "        output = torch.zeros((src.shape[0], tgt_len + 1, src.shape[2])).to(src.device)\n",
    "        output[:, 0] = src[:, -1]\n",
    "        for i in range(tgt_len):\n",
    "            output[:, i + 1] = self.forward(src, output)[:, i]\n",
    "\n",
    "        return output[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55898f03-8f68-4828-be9d-ffe065f95960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_partition_data(\n",
    "    data_path: Path, seq_length: int = 100\n",
    ") -> tuple[np.ndarray, int]:\n",
    "    \"\"\"Loads the given data and paritions it into sequences of equal length.\n",
    "\n",
    "    Args:\n",
    "        data_path: path to the dataset\n",
    "        sequence_length: length of the generated sequences\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, int]: tuple of generated sequences and number of\n",
    "            features in dataset\n",
    "    \"\"\"\n",
    "    data = np.load(data_path)\n",
    "    num_features = len(data.keys())\n",
    "\n",
    "    # Check that each feature provides the same number of data points\n",
    "    data_lens = [len(data[key]) for key in data.keys()]\n",
    "    assert len(set(data_lens)) == 1\n",
    "\n",
    "    num_sequences = data_lens[0] // seq_length\n",
    "    sequences = np.empty((num_sequences, seq_length, num_features))\n",
    "\n",
    "    for i in range(0, num_sequences):\n",
    "        # [sequence_length, num_features]\n",
    "        sample = np.asarray(\n",
    "            [data[key][i * seq_length : (i + 1) * seq_length] for key in data.keys()]\n",
    "        ).swapaxes(0, 1)\n",
    "        sequences[i] = sample\n",
    "\n",
    "    return sequences, num_features\n",
    "\n",
    "\n",
    "def make_datasets(sequences: np.ndarray) -> tuple[TensorDataset, TensorDataset]:\n",
    "    \"\"\"Create train and test dataset.\n",
    "\n",
    "    Args:\n",
    "        sequences: sequences to use [num_sequences, sequence_length, num_features]\n",
    "\n",
    "    Returns:\n",
    "        tuple[TensorDataset, TensorDataset]: train and test dataset\n",
    "    \"\"\"\n",
    "    # Split sequences into train and test split\n",
    "    train, test = train_test_split(sequences, test_size=0.2)\n",
    "    return TensorDataset(torch.Tensor(train)), TensorDataset(torch.Tensor(test))\n",
    "\n",
    "\n",
    "def visualize(\n",
    "    src: torch.Tensor,\n",
    "    tgt: torch.Tensor,\n",
    "    pred: torch.Tensor,\n",
    "    pred_infer: torch.Tensor,\n",
    "    idx=0,\n",
    ") -> None:\n",
    "    \"\"\"Visualizes a given sample including predictions.\n",
    "\n",
    "    Args:\n",
    "        src: source sequence [bs, src_seq_len, num_features]\n",
    "        tgt: target sequence [bs, tgt_seq_len, num_features]\n",
    "        pred: prediction of the model [bs, tgt_seq_len, num_features]\n",
    "        pred_infer: prediction obtained by running inference\n",
    "            [bs, tgt_seq_len, num_features]\n",
    "        idx: batch index to visualize\n",
    "    \"\"\"\n",
    "    x = np.arange(src.shape[1] + tgt.shape[1])\n",
    "    src_len = src.shape[1]\n",
    "\n",
    "    plt.plot(x[:src_len], src[idx].cpu().detach(), \"bo-\", label=\"src\")\n",
    "    plt.plot(x[src_len:], tgt[idx].cpu().detach(), \"go-\", label=\"tgt\")\n",
    "    plt.plot(x[src_len:], pred[idx].cpu().detach(), \"ro-\", label=\"pred\")\n",
    "    plt.plot(x[src_len:], pred_infer[idx].cpu().detach(), \"yo-\", label=\"pred_infer\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def split_sequence(\n",
    "    sequence: np.ndarray, ratio: float = 0.8\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Splits a sequence into 2 (3) parts, as is required by our transformer\n",
    "    model.\n",
    "\n",
    "    Assume our sequence length is L, we then split this into src of length N\n",
    "    and tgt_y of length M, with N + M = L.\n",
    "    src, the first part of the input sequence, is the input to the encoder, and we\n",
    "    expect the decoder to predict tgt_y, the second part of the input sequence.\n",
    "    In addition we generate tgt, which is tgt_y but \"shifted left\" by one - i.e. it\n",
    "    starts with the last token of src, and ends with the second-last token in tgt_y.\n",
    "    This sequence will be the input to the decoder.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        sequence: batched input sequences to split [bs, seq_len, num_features]\n",
    "        ratio: split ratio, N = ratio * L\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor, torch.Tensor]: src, tgt, tgt_y\n",
    "    \"\"\"\n",
    "    src_end = int(sequence.shape[1] * ratio)\n",
    "    # [bs, src_seq_len, num_features]\n",
    "    src = sequence[:, :src_end]\n",
    "    # [bs, tgt_seq_len, num_features]\n",
    "    tgt = sequence[:, src_end - 1 : -1]\n",
    "    # [bs, tgt_seq_len, num_features]\n",
    "    tgt_y = sequence[:, src_end:]\n",
    "\n",
    "    return src, tgt, tgt_y\n",
    "\n",
    "\n",
    "def move_to_device(device: torch.Tensor, *tensors: torch.Tensor) -> list[torch.Tensor]:\n",
    "    \"\"\"Move all given tensors to the given device.\n",
    "\n",
    "    Args:\n",
    "        device: device to move tensors to\n",
    "        tensors: tensors to move\n",
    "\n",
    "    Returns:\n",
    "        list[torch.Tensor]: moved tensors\n",
    "    \"\"\"\n",
    "    moved_tensors = []\n",
    "    for tensor in tensors:\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            moved_tensors.append(tensor.to(device))\n",
    "        else:\n",
    "            moved_tensors.append(tensor)\n",
    "    return moved_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7ee2a-732d-4ebd-9e30-814020ea7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 100                                                                        # batch size\n",
    "FEATURE_DIM = 128                                                               # dimensionality of input features\n",
    "NUM_HEADS = 8                                                                   # number of attention heads in the multi-head attention mechanism\n",
    "NUM_EPOCHS = 10                                                                 # number of times entire dataset is passed for training\n",
    "NUM_VIS_EXAMPLES = 1\n",
    "NUM_LAYERS = 2                                                                  # number of encoder and decoder layers in the mdel\n",
    "LR = 0.001  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900495bb-d790-4184-a0aa-4303564137ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and generate train and test datasets / dataloaders\n",
    "sequences, num_features = load_and_partition_data(\"test_correction_data_2019_mo1.npz\")               # change data file name\n",
    "train_set, test_set = make_datasets(sequences)\n",
    "train_loader, test_loader = DataLoader(\n",
    "    train_set, batch_size=BS, shuffle=True\n",
    "), DataLoader(test_set, batch_size=BS, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d63081-df7c-4726-bb97-33dee9012d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer and loss criterion\n",
    "model = TransformerWithPE(\n",
    "    num_features, num_features, FEATURE_DIM, NUM_HEADS, NUM_LAYERS\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb645fb5-d0af-4a48-8d13-7318d7df8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.0                                                            # initialize epoch loss\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src, tgt, tgt_y = split_sequence(batch[0])\n",
    "        src, tgt, tgt_y = move_to_device(device, src, tgt, tgt_y)\n",
    "        # [bs, tgt_seq_len, num_features]\n",
    "        pred = model(src, tgt)\n",
    "        loss = criterion(pred, tgt_y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: \"\n",
    "        f\"{(epoch_loss / len(train_loader)):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d8c78-f793-495d-b699-83d2199fea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "eval_loss = 0.0\n",
    "infer_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(test_loader):\n",
    "        src, tgt, tgt_y = split_sequence(batch[0])\n",
    "        src, tgt, tgt_y = move_to_device(device, src, tgt, tgt_y)\n",
    "\n",
    "        # [bs, tgt_seq_len, num_features]\n",
    "        pred = model(src, tgt)\n",
    "        loss = criterion(pred, tgt_y)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        # Run inference with model\n",
    "        pred_infer = model.infer(src, tgt.shape[1])\n",
    "        loss_infer = criterion(pred_infer, tgt_y)\n",
    "        infer_loss += loss_infer.item()\n",
    "\n",
    "        if idx < NUM_VIS_EXAMPLES:\n",
    "            visualize(src, tgt, pred, pred_infer)\n",
    "\n",
    "avg_eval_loss = eval_loss / len(test_loader)\n",
    "avg_infer_loss = infer_loss / len(test_loader)\n",
    "\n",
    "print(f\"Eval Loss on test set: {avg_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae2fa9-eab9-4061-a14c-7602b0577cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47bfd0d-b2a6-477c-92c4-b52eb77e784e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
